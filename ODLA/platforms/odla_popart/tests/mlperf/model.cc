//===- Halo Compiler Generated File --------------------------------===//

#include <ODLA/odla.h>

extern const odla_float16 Embedding_Embedding_Dict[30522 * 1024];
extern const odla_float16 Embedding_Segment_Dict[2 * 1024];
extern const odla_float16 Embedding_Positional_Dict[512 * 1024];
extern const odla_float16 Embedding_Gamma[1024];
extern const odla_float16 Embedding_Beta[1024];
extern const odla_float16 Layer0_Attention_Q[1024 * 1024];
extern const odla_float16 Layer0_Attention_K[1024 * 1024];
extern const odla_float16 Layer0_Attention_V[1024 * 1024];
extern const odla_float16 Layer0_Attention_Out[1024 * 1024];
extern const odla_float16 Layer0_Attention_Out_Bias[1024];
extern const odla_float16 Layer0_Attention_Gamma[1024];
extern const odla_float16 Layer0_Attention_Beta[1024];
extern const odla_float16 Layer0_FF_1_W[1024 * 4096];
extern const odla_float16 Layer0_FF_1_B[4096];
extern const odla_float16 Layer0_FF_2_W[4096 * 1024];
extern const odla_float16 Layer0_FF_2_B[1024];
extern const odla_float16 Layer0_FF_Gamma[1024];
extern const odla_float16 Layer0_FF_Beta[1024];
extern const odla_float16 Layer1_Attention_Q[1024 * 1024];
extern const odla_float16 Layer1_Attention_K[1024 * 1024];
extern const odla_float16 Layer1_Attention_V[1024 * 1024];
extern const odla_float16 Layer1_Attention_Out[1024 * 1024];
extern const odla_float16 Layer1_Attention_Out_Bias[1024];
extern const odla_float16 Layer1_Attention_Gamma[1024];
extern const odla_float16 Layer1_Attention_Beta[1024];
extern const odla_float16 Layer1_FF_1_W[1024 * 4096];
extern const odla_float16 Layer1_FF_1_B[4096];
extern const odla_float16 Layer1_FF_2_W[4096 * 1024];
extern const odla_float16 Layer1_FF_2_B[1024];
extern const odla_float16 Layer1_FF_Gamma[1024];
extern const odla_float16 Layer1_FF_Beta[1024];
extern const odla_float16 Layer2_Attention_Q[1024 * 1024];
extern const odla_float16 Layer2_Attention_K[1024 * 1024];
extern const odla_float16 Layer2_Attention_V[1024 * 1024];
extern const odla_float16 Layer2_Attention_Out[1024 * 1024];
extern const odla_float16 Layer2_Attention_Out_Bias[1024];
extern const odla_float16 Layer2_Attention_Gamma[1024];
extern const odla_float16 Layer2_Attention_Beta[1024];
extern const odla_float16 Layer2_FF_1_W[1024 * 4096];
extern const odla_float16 Layer2_FF_1_B[4096];
extern const odla_float16 Layer2_FF_2_W[4096 * 1024];
extern const odla_float16 Layer2_FF_2_B[1024];
extern const odla_float16 Layer2_FF_Gamma[1024];
extern const odla_float16 Layer2_FF_Beta[1024];
extern const odla_float16 Layer3_Attention_Q[1024 * 1024];
extern const odla_float16 Layer3_Attention_K[1024 * 1024];
extern const odla_float16 Layer3_Attention_V[1024 * 1024];
extern const odla_float16 Layer3_Attention_Out[1024 * 1024];
extern const odla_float16 Layer3_Attention_Out_Bias[1024];
extern const odla_float16 Layer3_Attention_Gamma[1024];
extern const odla_float16 Layer3_Attention_Beta[1024];
extern const odla_float16 Layer3_FF_1_W[1024 * 4096];
extern const odla_float16 Layer3_FF_1_B[4096];
extern const odla_float16 Layer3_FF_2_W[4096 * 1024];
extern const odla_float16 Layer3_FF_2_B[1024];
extern const odla_float16 Layer3_FF_Gamma[1024];
extern const odla_float16 Layer3_FF_Beta[1024];
extern const odla_float16 Layer4_Attention_Q[1024 * 1024];
extern const odla_float16 Layer4_Attention_K[1024 * 1024];
extern const odla_float16 Layer4_Attention_V[1024 * 1024];
extern const odla_float16 Layer4_Attention_Out[1024 * 1024];
extern const odla_float16 Layer4_Attention_Out_Bias[1024];
extern const odla_float16 Layer4_Attention_Gamma[1024];
extern const odla_float16 Layer4_Attention_Beta[1024];
extern const odla_float16 Layer4_FF_1_W[1024 * 4096];
extern const odla_float16 Layer4_FF_1_B[4096];
extern const odla_float16 Layer4_FF_2_W[4096 * 1024];
extern const odla_float16 Layer4_FF_2_B[1024];
extern const odla_float16 Layer4_FF_Gamma[1024];
extern const odla_float16 Layer4_FF_Beta[1024];
extern const odla_float16 Layer5_Attention_Q[1024 * 1024];
extern const odla_float16 Layer5_Attention_K[1024 * 1024];
extern const odla_float16 Layer5_Attention_V[1024 * 1024];
extern const odla_float16 Layer5_Attention_Out[1024 * 1024];
extern const odla_float16 Layer5_Attention_Out_Bias[1024];
extern const odla_float16 Layer5_Attention_Gamma[1024];
extern const odla_float16 Layer5_Attention_Beta[1024];
extern const odla_float16 Layer5_FF_1_W[1024 * 4096];
extern const odla_float16 Layer5_FF_1_B[4096];
extern const odla_float16 Layer5_FF_2_W[4096 * 1024];
extern const odla_float16 Layer5_FF_2_B[1024];
extern const odla_float16 Layer5_FF_Gamma[1024];
extern const odla_float16 Layer5_FF_Beta[1024];
extern const odla_float16 Layer6_Attention_Q[1024 * 1024];
extern const odla_float16 Layer6_Attention_K[1024 * 1024];
extern const odla_float16 Layer6_Attention_V[1024 * 1024];
extern const odla_float16 Layer6_Attention_Out[1024 * 1024];
extern const odla_float16 Layer6_Attention_Out_Bias[1024];
extern const odla_float16 Layer6_Attention_Gamma[1024];
extern const odla_float16 Layer6_Attention_Beta[1024];
extern const odla_float16 Layer6_FF_1_W[1024 * 4096];
extern const odla_float16 Layer6_FF_1_B[4096];
extern const odla_float16 Layer6_FF_2_W[4096 * 1024];
extern const odla_float16 Layer6_FF_2_B[1024];
extern const odla_float16 Layer6_FF_Gamma[1024];
extern const odla_float16 Layer6_FF_Beta[1024];
extern const odla_float16 Layer7_Attention_Q[1024 * 1024];
extern const odla_float16 Layer7_Attention_K[1024 * 1024];
extern const odla_float16 Layer7_Attention_V[1024 * 1024];
extern const odla_float16 Layer7_Attention_Out[1024 * 1024];
extern const odla_float16 Layer7_Attention_Out_Bias[1024];
extern const odla_float16 Layer7_Attention_Gamma[1024];
extern const odla_float16 Layer7_Attention_Beta[1024];
extern const odla_float16 Layer7_FF_1_W[1024 * 4096];
extern const odla_float16 Layer7_FF_1_B[4096];
extern const odla_float16 Layer7_FF_2_W[4096 * 1024];
extern const odla_float16 Layer7_FF_2_B[1024];
extern const odla_float16 Layer7_FF_Gamma[1024];
extern const odla_float16 Layer7_FF_Beta[1024];
extern const odla_float16 Layer8_Attention_Q[1024 * 1024];
extern const odla_float16 Layer8_Attention_K[1024 * 1024];
extern const odla_float16 Layer8_Attention_V[1024 * 1024];
extern const odla_float16 Layer8_Attention_Out[1024 * 1024];
extern const odla_float16 Layer8_Attention_Out_Bias[1024];
extern const odla_float16 Layer8_Attention_Gamma[1024];
extern const odla_float16 Layer8_Attention_Beta[1024];
extern const odla_float16 Layer8_FF_1_W[1024 * 4096];
extern const odla_float16 Layer8_FF_1_B[4096];
extern const odla_float16 Layer8_FF_2_W[4096 * 1024];
extern const odla_float16 Layer8_FF_2_B[1024];
extern const odla_float16 Layer8_FF_Gamma[1024];
extern const odla_float16 Layer8_FF_Beta[1024];
extern const odla_float16 Layer9_Attention_Q[1024 * 1024];
extern const odla_float16 Layer9_Attention_K[1024 * 1024];
extern const odla_float16 Layer9_Attention_V[1024 * 1024];
extern const odla_float16 Layer9_Attention_Out[1024 * 1024];
extern const odla_float16 Layer9_Attention_Out_Bias[1024];
extern const odla_float16 Layer9_Attention_Gamma[1024];
extern const odla_float16 Layer9_Attention_Beta[1024];
extern const odla_float16 Layer9_FF_1_W[1024 * 4096];
extern const odla_float16 Layer9_FF_1_B[4096];
extern const odla_float16 Layer9_FF_2_W[4096 * 1024];
extern const odla_float16 Layer9_FF_2_B[1024];
extern const odla_float16 Layer9_FF_Gamma[1024];
extern const odla_float16 Layer9_FF_Beta[1024];
extern const odla_float16 Layer10_Attention_Q[1024 * 1024];
extern const odla_float16 Layer10_Attention_K[1024 * 1024];
extern const odla_float16 Layer10_Attention_V[1024 * 1024];
extern const odla_float16 Layer10_Attention_Out[1024 * 1024];
extern const odla_float16 Layer10_Attention_Out_Bias[1024];
extern const odla_float16 Layer10_Attention_Gamma[1024];
extern const odla_float16 Layer10_Attention_Beta[1024];
extern const odla_float16 Layer10_FF_1_W[1024 * 4096];
extern const odla_float16 Layer10_FF_1_B[4096];
extern const odla_float16 Layer10_FF_2_W[4096 * 1024];
extern const odla_float16 Layer10_FF_2_B[1024];
extern const odla_float16 Layer10_FF_Gamma[1024];
extern const odla_float16 Layer10_FF_Beta[1024];
extern const odla_float16 Layer11_Attention_Q[1024 * 1024];
extern const odla_float16 Layer11_Attention_K[1024 * 1024];
extern const odla_float16 Layer11_Attention_V[1024 * 1024];
extern const odla_float16 Layer11_Attention_Out[1024 * 1024];
extern const odla_float16 Layer11_Attention_Out_Bias[1024];
extern const odla_float16 Layer11_Attention_Gamma[1024];
extern const odla_float16 Layer11_Attention_Beta[1024];
extern const odla_float16 Layer11_FF_1_W[1024 * 4096];
extern const odla_float16 Layer11_FF_1_B[4096];
extern const odla_float16 Layer11_FF_2_W[4096 * 1024];
extern const odla_float16 Layer11_FF_2_B[1024];
extern const odla_float16 Layer11_FF_Gamma[1024];
extern const odla_float16 Layer11_FF_Beta[1024];
extern const odla_float16 Layer12_Attention_Q[1024 * 1024];
extern const odla_float16 Layer12_Attention_K[1024 * 1024];
extern const odla_float16 Layer12_Attention_V[1024 * 1024];
extern const odla_float16 Layer12_Attention_Out[1024 * 1024];
extern const odla_float16 Layer12_Attention_Out_Bias[1024];
extern const odla_float16 Layer12_Attention_Gamma[1024];
extern const odla_float16 Layer12_Attention_Beta[1024];
extern const odla_float16 Layer12_FF_1_W[1024 * 4096];
extern const odla_float16 Layer12_FF_1_B[4096];
extern const odla_float16 Layer12_FF_2_W[4096 * 1024];
extern const odla_float16 Layer12_FF_2_B[1024];
extern const odla_float16 Layer12_FF_Gamma[1024];
extern const odla_float16 Layer12_FF_Beta[1024];
extern const odla_float16 Layer13_Attention_Q[1024 * 1024];
extern const odla_float16 Layer13_Attention_K[1024 * 1024];
extern const odla_float16 Layer13_Attention_V[1024 * 1024];
extern const odla_float16 Layer13_Attention_Out[1024 * 1024];
extern const odla_float16 Layer13_Attention_Out_Bias[1024];
extern const odla_float16 Layer13_Attention_Gamma[1024];
extern const odla_float16 Layer13_Attention_Beta[1024];
extern const odla_float16 Layer13_FF_1_W[1024 * 4096];
extern const odla_float16 Layer13_FF_1_B[4096];
extern const odla_float16 Layer13_FF_2_W[4096 * 1024];
extern const odla_float16 Layer13_FF_2_B[1024];
extern const odla_float16 Layer13_FF_Gamma[1024];
extern const odla_float16 Layer13_FF_Beta[1024];
extern const odla_float16 Layer14_Attention_Q[1024 * 1024];
extern const odla_float16 Layer14_Attention_K[1024 * 1024];
extern const odla_float16 Layer14_Attention_V[1024 * 1024];
extern const odla_float16 Layer14_Attention_Out[1024 * 1024];
extern const odla_float16 Layer14_Attention_Out_Bias[1024];
extern const odla_float16 Layer14_Attention_Gamma[1024];
extern const odla_float16 Layer14_Attention_Beta[1024];
extern const odla_float16 Layer14_FF_1_W[1024 * 4096];
extern const odla_float16 Layer14_FF_1_B[4096];
extern const odla_float16 Layer14_FF_2_W[4096 * 1024];
extern const odla_float16 Layer14_FF_2_B[1024];
extern const odla_float16 Layer14_FF_Gamma[1024];
extern const odla_float16 Layer14_FF_Beta[1024];
extern const odla_float16 Layer15_Attention_Q[1024 * 1024];
extern const odla_float16 Layer15_Attention_K[1024 * 1024];
extern const odla_float16 Layer15_Attention_V[1024 * 1024];
extern const odla_float16 Layer15_Attention_Out[1024 * 1024];
extern const odla_float16 Layer15_Attention_Out_Bias[1024];
extern const odla_float16 Layer15_Attention_Gamma[1024];
extern const odla_float16 Layer15_Attention_Beta[1024];
extern const odla_float16 Layer15_FF_1_W[1024 * 4096];
extern const odla_float16 Layer15_FF_1_B[4096];
extern const odla_float16 Layer15_FF_2_W[4096 * 1024];
extern const odla_float16 Layer15_FF_2_B[1024];
extern const odla_float16 Layer15_FF_Gamma[1024];
extern const odla_float16 Layer15_FF_Beta[1024];
extern const odla_float16 Layer16_Attention_Q[1024 * 1024];
extern const odla_float16 Layer16_Attention_K[1024 * 1024];
extern const odla_float16 Layer16_Attention_V[1024 * 1024];
extern const odla_float16 Layer16_Attention_Out[1024 * 1024];
extern const odla_float16 Layer16_Attention_Out_Bias[1024];
extern const odla_float16 Layer16_Attention_Gamma[1024];
extern const odla_float16 Layer16_Attention_Beta[1024];
extern const odla_float16 Layer16_FF_1_W[1024 * 4096];
extern const odla_float16 Layer16_FF_1_B[4096];
extern const odla_float16 Layer16_FF_2_W[4096 * 1024];
extern const odla_float16 Layer16_FF_2_B[1024];
extern const odla_float16 Layer16_FF_Gamma[1024];
extern const odla_float16 Layer16_FF_Beta[1024];
extern const odla_float16 Layer17_Attention_Q[1024 * 1024];
extern const odla_float16 Layer17_Attention_K[1024 * 1024];
extern const odla_float16 Layer17_Attention_V[1024 * 1024];
extern const odla_float16 Layer17_Attention_Out[1024 * 1024];
extern const odla_float16 Layer17_Attention_Out_Bias[1024];
extern const odla_float16 Layer17_Attention_Gamma[1024];
extern const odla_float16 Layer17_Attention_Beta[1024];
extern const odla_float16 Layer17_FF_1_W[1024 * 4096];
extern const odla_float16 Layer17_FF_1_B[4096];
extern const odla_float16 Layer17_FF_2_W[4096 * 1024];
extern const odla_float16 Layer17_FF_2_B[1024];
extern const odla_float16 Layer17_FF_Gamma[1024];
extern const odla_float16 Layer17_FF_Beta[1024];
extern const odla_float16 Layer18_Attention_Q[1024 * 1024];
extern const odla_float16 Layer18_Attention_K[1024 * 1024];
extern const odla_float16 Layer18_Attention_V[1024 * 1024];
extern const odla_float16 Layer18_Attention_Out[1024 * 1024];
extern const odla_float16 Layer18_Attention_Out_Bias[1024];
extern const odla_float16 Layer18_Attention_Gamma[1024];
extern const odla_float16 Layer18_Attention_Beta[1024];
extern const odla_float16 Layer18_FF_1_W[1024 * 4096];
extern const odla_float16 Layer18_FF_1_B[4096];
extern const odla_float16 Layer18_FF_2_W[4096 * 1024];
extern const odla_float16 Layer18_FF_2_B[1024];
extern const odla_float16 Layer18_FF_Gamma[1024];
extern const odla_float16 Layer18_FF_Beta[1024];
extern const odla_float16 Layer19_Attention_Q[1024 * 1024];
extern const odla_float16 Layer19_Attention_K[1024 * 1024];
extern const odla_float16 Layer19_Attention_V[1024 * 1024];
extern const odla_float16 Layer19_Attention_Out[1024 * 1024];
extern const odla_float16 Layer19_Attention_Out_Bias[1024];
extern const odla_float16 Layer19_Attention_Gamma[1024];
extern const odla_float16 Layer19_Attention_Beta[1024];
extern const odla_float16 Layer19_FF_1_W[1024 * 4096];
extern const odla_float16 Layer19_FF_1_B[4096];
extern const odla_float16 Layer19_FF_2_W[4096 * 1024];
extern const odla_float16 Layer19_FF_2_B[1024];
extern const odla_float16 Layer19_FF_Gamma[1024];
extern const odla_float16 Layer19_FF_Beta[1024];
extern const odla_float16 Layer20_Attention_Q[1024 * 1024];
extern const odla_float16 Layer20_Attention_K[1024 * 1024];
extern const odla_float16 Layer20_Attention_V[1024 * 1024];
extern const odla_float16 Layer20_Attention_Out[1024 * 1024];
extern const odla_float16 Layer20_Attention_Out_Bias[1024];
extern const odla_float16 Layer20_Attention_Gamma[1024];
extern const odla_float16 Layer20_Attention_Beta[1024];
extern const odla_float16 Layer20_FF_1_W[1024 * 4096];
extern const odla_float16 Layer20_FF_1_B[4096];
extern const odla_float16 Layer20_FF_2_W[4096 * 1024];
extern const odla_float16 Layer20_FF_2_B[1024];
extern const odla_float16 Layer20_FF_Gamma[1024];
extern const odla_float16 Layer20_FF_Beta[1024];
extern const odla_float16 Layer21_Attention_Q[1024 * 1024];
extern const odla_float16 Layer21_Attention_K[1024 * 1024];
extern const odla_float16 Layer21_Attention_V[1024 * 1024];
extern const odla_float16 Layer21_Attention_Out[1024 * 1024];
extern const odla_float16 Layer21_Attention_Out_Bias[1024];
extern const odla_float16 Layer21_Attention_Gamma[1024];
extern const odla_float16 Layer21_Attention_Beta[1024];
extern const odla_float16 Layer21_FF_1_W[1024 * 4096];
extern const odla_float16 Layer21_FF_1_B[4096];
extern const odla_float16 Layer21_FF_2_W[4096 * 1024];
extern const odla_float16 Layer21_FF_2_B[1024];
extern const odla_float16 Layer21_FF_Gamma[1024];
extern const odla_float16 Layer21_FF_Beta[1024];
extern const odla_float16 Layer22_Attention_Q[1024 * 1024];
extern const odla_float16 Layer22_Attention_K[1024 * 1024];
extern const odla_float16 Layer22_Attention_V[1024 * 1024];
extern const odla_float16 Layer22_Attention_Out[1024 * 1024];
extern const odla_float16 Layer22_Attention_Out_Bias[1024];
extern const odla_float16 Layer22_Attention_Gamma[1024];
extern const odla_float16 Layer22_Attention_Beta[1024];
extern const odla_float16 Layer22_FF_1_W[1024 * 4096];
extern const odla_float16 Layer22_FF_1_B[4096];
extern const odla_float16 Layer22_FF_2_W[4096 * 1024];
extern const odla_float16 Layer22_FF_2_B[1024];
extern const odla_float16 Layer22_FF_Gamma[1024];
extern const odla_float16 Layer22_FF_Beta[1024];
extern const odla_float16 Layer23_Attention_Q[1024 * 1024];
extern const odla_float16 Layer23_Attention_K[1024 * 1024];
extern const odla_float16 Layer23_Attention_V[1024 * 1024];
extern const odla_float16 Layer23_Attention_Out[1024 * 1024];
extern const odla_float16 Layer23_Attention_Out_Bias[1024];
extern const odla_float16 Layer23_Attention_Gamma[1024];
extern const odla_float16 Layer23_Attention_Beta[1024];
extern const odla_float16 Layer23_FF_1_W[1024 * 4096];
extern const odla_float16 Layer23_FF_1_B[4096];
extern const odla_float16 Layer23_FF_2_W[4096 * 1024];
extern const odla_float16 Layer23_FF_2_B[1024];
extern const odla_float16 Layer23_FF_Gamma[1024];
extern const odla_float16 Layer23_FF_Beta[1024];
extern const odla_float16 Squad_SquadW[1024 * 2];
extern const odla_float16 Squad_SquadB[2];
extern const int Embedding_Constant_0[];
extern const odla_float16 Embedding_Constant_0_1[2];
extern const odla_float16 Embedding_OneHot_on_value[];
extern "C" {
int model_run(int num_inputs, const void *inputs[], int num_outputs,
              void *outputs[], int batch_size);
int model_init();
int model_fini();
int model_helper(odla_computation comp);
};
static odla_computation Comp;
int model_helper(odla_computation comp) {
  auto indices = odla_CreateArgument({ODLA_UINT32, {.size = 1, .dims = {3840}}},
                                     (const odla_value_id)("indices"));
  auto input_mask =
      odla_CreateArgument({ODLA_UINT32, {.size = 1, .dims = {3840}}},
                          (const odla_value_id)("input_mask"));
  auto positions =
      odla_CreateArgument({ODLA_UINT32, {.size = 1, .dims = {3840}}},
                          (const odla_value_id)("positions"));
  auto segments =
      odla_CreateArgument({ODLA_UINT32, {.size = 1, .dims = {3840}}},
                          (const odla_value_id)("segments"));
  auto Embedding_Embedding_Dict_ =
      odla_CreateConstant({ODLA_FLOAT16, {.size = 2, .dims = {30522, 1024}}},
                          Embedding_Embedding_Dict,
                          (const odla_value_id) "Embedding_Embedding_Dict_");
  auto Embedding_Segment_Dict_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {2, 1024}}}, Embedding_Segment_Dict,
      (const odla_value_id) "Embedding_Segment_Dict_");
  auto Embedding_Positional_Dict_ =
      odla_CreateConstant({ODLA_FLOAT16, {.size = 2, .dims = {512, 1024}}},
                          Embedding_Positional_Dict,
                          (const odla_value_id) "Embedding_Positional_Dict_");
  auto Embedding_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Embedding_Gamma,
      (const odla_value_id) "Embedding_Gamma_");
  auto Embedding_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Embedding_Beta,
      (const odla_value_id) "Embedding_Beta_");
  auto Layer0_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer0_Attention_Q,
      (const odla_value_id) "Layer0_Attention_Q_");
  auto Layer0_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer0_Attention_K,
      (const odla_value_id) "Layer0_Attention_K_");
  auto Layer0_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer0_Attention_V,
      (const odla_value_id) "Layer0_Attention_V_");
  auto Layer0_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer0_Attention_Out,
      (const odla_value_id) "Layer0_Attention_Out_");
  auto Layer0_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer0_Attention_Out_Bias,
      (const odla_value_id) "Layer0_Attention_Out_Bias_");
  auto Layer0_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer0_Attention_Gamma,
      (const odla_value_id) "Layer0_Attention_Gamma_");
  auto Layer0_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer0_Attention_Beta,
      (const odla_value_id) "Layer0_Attention_Beta_");
  auto Layer0_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer0_FF_1_W,
      (const odla_value_id) "Layer0_FF_1_W_");
  auto Layer0_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer0_FF_1_B,
      (const odla_value_id) "Layer0_FF_1_B_");
  auto Layer0_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer0_FF_2_W,
      (const odla_value_id) "Layer0_FF_2_W_");
  auto Layer0_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer0_FF_2_B,
      (const odla_value_id) "Layer0_FF_2_B_");
  auto Layer0_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer0_FF_Gamma,
      (const odla_value_id) "Layer0_FF_Gamma_");
  auto Layer0_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer0_FF_Beta,
      (const odla_value_id) "Layer0_FF_Beta_");
  auto Layer1_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer1_Attention_Q,
      (const odla_value_id) "Layer1_Attention_Q_");
  auto Layer1_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer1_Attention_K,
      (const odla_value_id) "Layer1_Attention_K_");
  auto Layer1_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer1_Attention_V,
      (const odla_value_id) "Layer1_Attention_V_");
  auto Layer1_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer1_Attention_Out,
      (const odla_value_id) "Layer1_Attention_Out_");
  auto Layer1_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer1_Attention_Out_Bias,
      (const odla_value_id) "Layer1_Attention_Out_Bias_");
  auto Layer1_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer1_Attention_Gamma,
      (const odla_value_id) "Layer1_Attention_Gamma_");
  auto Layer1_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer1_Attention_Beta,
      (const odla_value_id) "Layer1_Attention_Beta_");
  auto Layer1_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer1_FF_1_W,
      (const odla_value_id) "Layer1_FF_1_W_");
  auto Layer1_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer1_FF_1_B,
      (const odla_value_id) "Layer1_FF_1_B_");
  auto Layer1_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer1_FF_2_W,
      (const odla_value_id) "Layer1_FF_2_W_");
  auto Layer1_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer1_FF_2_B,
      (const odla_value_id) "Layer1_FF_2_B_");
  auto Layer1_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer1_FF_Gamma,
      (const odla_value_id) "Layer1_FF_Gamma_");
  auto Layer1_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer1_FF_Beta,
      (const odla_value_id) "Layer1_FF_Beta_");
  auto Layer2_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer2_Attention_Q,
      (const odla_value_id) "Layer2_Attention_Q_");
  auto Layer2_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer2_Attention_K,
      (const odla_value_id) "Layer2_Attention_K_");
  auto Layer2_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer2_Attention_V,
      (const odla_value_id) "Layer2_Attention_V_");
  auto Layer2_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer2_Attention_Out,
      (const odla_value_id) "Layer2_Attention_Out_");
  auto Layer2_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer2_Attention_Out_Bias,
      (const odla_value_id) "Layer2_Attention_Out_Bias_");
  auto Layer2_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer2_Attention_Gamma,
      (const odla_value_id) "Layer2_Attention_Gamma_");
  auto Layer2_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer2_Attention_Beta,
      (const odla_value_id) "Layer2_Attention_Beta_");
  auto Layer2_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer2_FF_1_W,
      (const odla_value_id) "Layer2_FF_1_W_");
  auto Layer2_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer2_FF_1_B,
      (const odla_value_id) "Layer2_FF_1_B_");
  auto Layer2_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer2_FF_2_W,
      (const odla_value_id) "Layer2_FF_2_W_");
  auto Layer2_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer2_FF_2_B,
      (const odla_value_id) "Layer2_FF_2_B_");
  auto Layer2_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer2_FF_Gamma,
      (const odla_value_id) "Layer2_FF_Gamma_");
  auto Layer2_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer2_FF_Beta,
      (const odla_value_id) "Layer2_FF_Beta_");
  auto Layer3_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer3_Attention_Q,
      (const odla_value_id) "Layer3_Attention_Q_");
  auto Layer3_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer3_Attention_K,
      (const odla_value_id) "Layer3_Attention_K_");
  auto Layer3_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer3_Attention_V,
      (const odla_value_id) "Layer3_Attention_V_");
  auto Layer3_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer3_Attention_Out,
      (const odla_value_id) "Layer3_Attention_Out_");
  auto Layer3_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer3_Attention_Out_Bias,
      (const odla_value_id) "Layer3_Attention_Out_Bias_");
  auto Layer3_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer3_Attention_Gamma,
      (const odla_value_id) "Layer3_Attention_Gamma_");
  auto Layer3_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer3_Attention_Beta,
      (const odla_value_id) "Layer3_Attention_Beta_");
  auto Layer3_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer3_FF_1_W,
      (const odla_value_id) "Layer3_FF_1_W_");
  auto Layer3_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer3_FF_1_B,
      (const odla_value_id) "Layer3_FF_1_B_");
  auto Layer3_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer3_FF_2_W,
      (const odla_value_id) "Layer3_FF_2_W_");
  auto Layer3_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer3_FF_2_B,
      (const odla_value_id) "Layer3_FF_2_B_");
  auto Layer3_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer3_FF_Gamma,
      (const odla_value_id) "Layer3_FF_Gamma_");
  auto Layer3_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer3_FF_Beta,
      (const odla_value_id) "Layer3_FF_Beta_");
  auto Layer4_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer4_Attention_Q,
      (const odla_value_id) "Layer4_Attention_Q_");
  auto Layer4_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer4_Attention_K,
      (const odla_value_id) "Layer4_Attention_K_");
  auto Layer4_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer4_Attention_V,
      (const odla_value_id) "Layer4_Attention_V_");
  auto Layer4_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer4_Attention_Out,
      (const odla_value_id) "Layer4_Attention_Out_");
  auto Layer4_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer4_Attention_Out_Bias,
      (const odla_value_id) "Layer4_Attention_Out_Bias_");
  auto Layer4_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer4_Attention_Gamma,
      (const odla_value_id) "Layer4_Attention_Gamma_");
  auto Layer4_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer4_Attention_Beta,
      (const odla_value_id) "Layer4_Attention_Beta_");
  auto Layer4_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer4_FF_1_W,
      (const odla_value_id) "Layer4_FF_1_W_");
  auto Layer4_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer4_FF_1_B,
      (const odla_value_id) "Layer4_FF_1_B_");
  auto Layer4_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer4_FF_2_W,
      (const odla_value_id) "Layer4_FF_2_W_");
  auto Layer4_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer4_FF_2_B,
      (const odla_value_id) "Layer4_FF_2_B_");
  auto Layer4_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer4_FF_Gamma,
      (const odla_value_id) "Layer4_FF_Gamma_");
  auto Layer4_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer4_FF_Beta,
      (const odla_value_id) "Layer4_FF_Beta_");
  auto Layer5_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer5_Attention_Q,
      (const odla_value_id) "Layer5_Attention_Q_");
  auto Layer5_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer5_Attention_K,
      (const odla_value_id) "Layer5_Attention_K_");
  auto Layer5_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer5_Attention_V,
      (const odla_value_id) "Layer5_Attention_V_");
  auto Layer5_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer5_Attention_Out,
      (const odla_value_id) "Layer5_Attention_Out_");
  auto Layer5_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer5_Attention_Out_Bias,
      (const odla_value_id) "Layer5_Attention_Out_Bias_");
  auto Layer5_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer5_Attention_Gamma,
      (const odla_value_id) "Layer5_Attention_Gamma_");
  auto Layer5_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer5_Attention_Beta,
      (const odla_value_id) "Layer5_Attention_Beta_");
  auto Layer5_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer5_FF_1_W,
      (const odla_value_id) "Layer5_FF_1_W_");
  auto Layer5_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer5_FF_1_B,
      (const odla_value_id) "Layer5_FF_1_B_");
  auto Layer5_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer5_FF_2_W,
      (const odla_value_id) "Layer5_FF_2_W_");
  auto Layer5_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer5_FF_2_B,
      (const odla_value_id) "Layer5_FF_2_B_");
  auto Layer5_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer5_FF_Gamma,
      (const odla_value_id) "Layer5_FF_Gamma_");
  auto Layer5_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer5_FF_Beta,
      (const odla_value_id) "Layer5_FF_Beta_");
  auto Layer6_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer6_Attention_Q,
      (const odla_value_id) "Layer6_Attention_Q_");
  auto Layer6_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer6_Attention_K,
      (const odla_value_id) "Layer6_Attention_K_");
  auto Layer6_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer6_Attention_V,
      (const odla_value_id) "Layer6_Attention_V_");
  auto Layer6_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer6_Attention_Out,
      (const odla_value_id) "Layer6_Attention_Out_");
  auto Layer6_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer6_Attention_Out_Bias,
      (const odla_value_id) "Layer6_Attention_Out_Bias_");
  auto Layer6_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer6_Attention_Gamma,
      (const odla_value_id) "Layer6_Attention_Gamma_");
  auto Layer6_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer6_Attention_Beta,
      (const odla_value_id) "Layer6_Attention_Beta_");
  auto Layer6_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer6_FF_1_W,
      (const odla_value_id) "Layer6_FF_1_W_");
  auto Layer6_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer6_FF_1_B,
      (const odla_value_id) "Layer6_FF_1_B_");
  auto Layer6_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer6_FF_2_W,
      (const odla_value_id) "Layer6_FF_2_W_");
  auto Layer6_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer6_FF_2_B,
      (const odla_value_id) "Layer6_FF_2_B_");
  auto Layer6_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer6_FF_Gamma,
      (const odla_value_id) "Layer6_FF_Gamma_");
  auto Layer6_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer6_FF_Beta,
      (const odla_value_id) "Layer6_FF_Beta_");
  auto Layer7_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer7_Attention_Q,
      (const odla_value_id) "Layer7_Attention_Q_");
  auto Layer7_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer7_Attention_K,
      (const odla_value_id) "Layer7_Attention_K_");
  auto Layer7_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer7_Attention_V,
      (const odla_value_id) "Layer7_Attention_V_");
  auto Layer7_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer7_Attention_Out,
      (const odla_value_id) "Layer7_Attention_Out_");
  auto Layer7_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer7_Attention_Out_Bias,
      (const odla_value_id) "Layer7_Attention_Out_Bias_");
  auto Layer7_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer7_Attention_Gamma,
      (const odla_value_id) "Layer7_Attention_Gamma_");
  auto Layer7_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer7_Attention_Beta,
      (const odla_value_id) "Layer7_Attention_Beta_");
  auto Layer7_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer7_FF_1_W,
      (const odla_value_id) "Layer7_FF_1_W_");
  auto Layer7_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer7_FF_1_B,
      (const odla_value_id) "Layer7_FF_1_B_");
  auto Layer7_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer7_FF_2_W,
      (const odla_value_id) "Layer7_FF_2_W_");
  auto Layer7_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer7_FF_2_B,
      (const odla_value_id) "Layer7_FF_2_B_");
  auto Layer7_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer7_FF_Gamma,
      (const odla_value_id) "Layer7_FF_Gamma_");
  auto Layer7_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer7_FF_Beta,
      (const odla_value_id) "Layer7_FF_Beta_");
  auto Layer8_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer8_Attention_Q,
      (const odla_value_id) "Layer8_Attention_Q_");
  auto Layer8_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer8_Attention_K,
      (const odla_value_id) "Layer8_Attention_K_");
  auto Layer8_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer8_Attention_V,
      (const odla_value_id) "Layer8_Attention_V_");
  auto Layer8_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer8_Attention_Out,
      (const odla_value_id) "Layer8_Attention_Out_");
  auto Layer8_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer8_Attention_Out_Bias,
      (const odla_value_id) "Layer8_Attention_Out_Bias_");
  auto Layer8_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer8_Attention_Gamma,
      (const odla_value_id) "Layer8_Attention_Gamma_");
  auto Layer8_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer8_Attention_Beta,
      (const odla_value_id) "Layer8_Attention_Beta_");
  auto Layer8_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer8_FF_1_W,
      (const odla_value_id) "Layer8_FF_1_W_");
  auto Layer8_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer8_FF_1_B,
      (const odla_value_id) "Layer8_FF_1_B_");
  auto Layer8_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer8_FF_2_W,
      (const odla_value_id) "Layer8_FF_2_W_");
  auto Layer8_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer8_FF_2_B,
      (const odla_value_id) "Layer8_FF_2_B_");
  auto Layer8_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer8_FF_Gamma,
      (const odla_value_id) "Layer8_FF_Gamma_");
  auto Layer8_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer8_FF_Beta,
      (const odla_value_id) "Layer8_FF_Beta_");
  auto Layer9_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer9_Attention_Q,
      (const odla_value_id) "Layer9_Attention_Q_");
  auto Layer9_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer9_Attention_K,
      (const odla_value_id) "Layer9_Attention_K_");
  auto Layer9_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer9_Attention_V,
      (const odla_value_id) "Layer9_Attention_V_");
  auto Layer9_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer9_Attention_Out,
      (const odla_value_id) "Layer9_Attention_Out_");
  auto Layer9_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer9_Attention_Out_Bias,
      (const odla_value_id) "Layer9_Attention_Out_Bias_");
  auto Layer9_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer9_Attention_Gamma,
      (const odla_value_id) "Layer9_Attention_Gamma_");
  auto Layer9_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer9_Attention_Beta,
      (const odla_value_id) "Layer9_Attention_Beta_");
  auto Layer9_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer9_FF_1_W,
      (const odla_value_id) "Layer9_FF_1_W_");
  auto Layer9_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer9_FF_1_B,
      (const odla_value_id) "Layer9_FF_1_B_");
  auto Layer9_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer9_FF_2_W,
      (const odla_value_id) "Layer9_FF_2_W_");
  auto Layer9_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer9_FF_2_B,
      (const odla_value_id) "Layer9_FF_2_B_");
  auto Layer9_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer9_FF_Gamma,
      (const odla_value_id) "Layer9_FF_Gamma_");
  auto Layer9_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer9_FF_Beta,
      (const odla_value_id) "Layer9_FF_Beta_");
  auto Layer10_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer10_Attention_Q,
      (const odla_value_id) "Layer10_Attention_Q_");
  auto Layer10_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer10_Attention_K,
      (const odla_value_id) "Layer10_Attention_K_");
  auto Layer10_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer10_Attention_V,
      (const odla_value_id) "Layer10_Attention_V_");
  auto Layer10_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer10_Attention_Out,
      (const odla_value_id) "Layer10_Attention_Out_");
  auto Layer10_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer10_Attention_Out_Bias,
      (const odla_value_id) "Layer10_Attention_Out_Bias_");
  auto Layer10_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer10_Attention_Gamma,
      (const odla_value_id) "Layer10_Attention_Gamma_");
  auto Layer10_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer10_Attention_Beta,
      (const odla_value_id) "Layer10_Attention_Beta_");
  auto Layer10_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer10_FF_1_W,
      (const odla_value_id) "Layer10_FF_1_W_");
  auto Layer10_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer10_FF_1_B,
      (const odla_value_id) "Layer10_FF_1_B_");
  auto Layer10_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer10_FF_2_W,
      (const odla_value_id) "Layer10_FF_2_W_");
  auto Layer10_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer10_FF_2_B,
      (const odla_value_id) "Layer10_FF_2_B_");
  auto Layer10_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer10_FF_Gamma,
      (const odla_value_id) "Layer10_FF_Gamma_");
  auto Layer10_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer10_FF_Beta,
      (const odla_value_id) "Layer10_FF_Beta_");
  auto Layer11_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer11_Attention_Q,
      (const odla_value_id) "Layer11_Attention_Q_");
  auto Layer11_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer11_Attention_K,
      (const odla_value_id) "Layer11_Attention_K_");
  auto Layer11_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer11_Attention_V,
      (const odla_value_id) "Layer11_Attention_V_");
  auto Layer11_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer11_Attention_Out,
      (const odla_value_id) "Layer11_Attention_Out_");
  auto Layer11_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer11_Attention_Out_Bias,
      (const odla_value_id) "Layer11_Attention_Out_Bias_");
  auto Layer11_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer11_Attention_Gamma,
      (const odla_value_id) "Layer11_Attention_Gamma_");
  auto Layer11_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer11_Attention_Beta,
      (const odla_value_id) "Layer11_Attention_Beta_");
  auto Layer11_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer11_FF_1_W,
      (const odla_value_id) "Layer11_FF_1_W_");
  auto Layer11_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer11_FF_1_B,
      (const odla_value_id) "Layer11_FF_1_B_");
  auto Layer11_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer11_FF_2_W,
      (const odla_value_id) "Layer11_FF_2_W_");
  auto Layer11_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer11_FF_2_B,
      (const odla_value_id) "Layer11_FF_2_B_");
  auto Layer11_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer11_FF_Gamma,
      (const odla_value_id) "Layer11_FF_Gamma_");
  auto Layer11_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer11_FF_Beta,
      (const odla_value_id) "Layer11_FF_Beta_");
  auto Layer12_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer12_Attention_Q,
      (const odla_value_id) "Layer12_Attention_Q_");
  auto Layer12_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer12_Attention_K,
      (const odla_value_id) "Layer12_Attention_K_");
  auto Layer12_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer12_Attention_V,
      (const odla_value_id) "Layer12_Attention_V_");
  auto Layer12_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer12_Attention_Out,
      (const odla_value_id) "Layer12_Attention_Out_");
  auto Layer12_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer12_Attention_Out_Bias,
      (const odla_value_id) "Layer12_Attention_Out_Bias_");
  auto Layer12_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer12_Attention_Gamma,
      (const odla_value_id) "Layer12_Attention_Gamma_");
  auto Layer12_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer12_Attention_Beta,
      (const odla_value_id) "Layer12_Attention_Beta_");
  auto Layer12_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer12_FF_1_W,
      (const odla_value_id) "Layer12_FF_1_W_");
  auto Layer12_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer12_FF_1_B,
      (const odla_value_id) "Layer12_FF_1_B_");
  auto Layer12_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer12_FF_2_W,
      (const odla_value_id) "Layer12_FF_2_W_");
  auto Layer12_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer12_FF_2_B,
      (const odla_value_id) "Layer12_FF_2_B_");
  auto Layer12_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer12_FF_Gamma,
      (const odla_value_id) "Layer12_FF_Gamma_");
  auto Layer12_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer12_FF_Beta,
      (const odla_value_id) "Layer12_FF_Beta_");
  auto Layer13_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer13_Attention_Q,
      (const odla_value_id) "Layer13_Attention_Q_");
  auto Layer13_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer13_Attention_K,
      (const odla_value_id) "Layer13_Attention_K_");
  auto Layer13_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer13_Attention_V,
      (const odla_value_id) "Layer13_Attention_V_");
  auto Layer13_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer13_Attention_Out,
      (const odla_value_id) "Layer13_Attention_Out_");
  auto Layer13_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer13_Attention_Out_Bias,
      (const odla_value_id) "Layer13_Attention_Out_Bias_");
  auto Layer13_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer13_Attention_Gamma,
      (const odla_value_id) "Layer13_Attention_Gamma_");
  auto Layer13_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer13_Attention_Beta,
      (const odla_value_id) "Layer13_Attention_Beta_");
  auto Layer13_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer13_FF_1_W,
      (const odla_value_id) "Layer13_FF_1_W_");
  auto Layer13_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer13_FF_1_B,
      (const odla_value_id) "Layer13_FF_1_B_");
  auto Layer13_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer13_FF_2_W,
      (const odla_value_id) "Layer13_FF_2_W_");
  auto Layer13_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer13_FF_2_B,
      (const odla_value_id) "Layer13_FF_2_B_");
  auto Layer13_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer13_FF_Gamma,
      (const odla_value_id) "Layer13_FF_Gamma_");
  auto Layer13_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer13_FF_Beta,
      (const odla_value_id) "Layer13_FF_Beta_");
  auto Layer14_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer14_Attention_Q,
      (const odla_value_id) "Layer14_Attention_Q_");
  auto Layer14_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer14_Attention_K,
      (const odla_value_id) "Layer14_Attention_K_");
  auto Layer14_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer14_Attention_V,
      (const odla_value_id) "Layer14_Attention_V_");
  auto Layer14_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer14_Attention_Out,
      (const odla_value_id) "Layer14_Attention_Out_");
  auto Layer14_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer14_Attention_Out_Bias,
      (const odla_value_id) "Layer14_Attention_Out_Bias_");
  auto Layer14_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer14_Attention_Gamma,
      (const odla_value_id) "Layer14_Attention_Gamma_");
  auto Layer14_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer14_Attention_Beta,
      (const odla_value_id) "Layer14_Attention_Beta_");
  auto Layer14_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer14_FF_1_W,
      (const odla_value_id) "Layer14_FF_1_W_");
  auto Layer14_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer14_FF_1_B,
      (const odla_value_id) "Layer14_FF_1_B_");
  auto Layer14_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer14_FF_2_W,
      (const odla_value_id) "Layer14_FF_2_W_");
  auto Layer14_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer14_FF_2_B,
      (const odla_value_id) "Layer14_FF_2_B_");
  auto Layer14_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer14_FF_Gamma,
      (const odla_value_id) "Layer14_FF_Gamma_");
  auto Layer14_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer14_FF_Beta,
      (const odla_value_id) "Layer14_FF_Beta_");
  auto Layer15_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer15_Attention_Q,
      (const odla_value_id) "Layer15_Attention_Q_");
  auto Layer15_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer15_Attention_K,
      (const odla_value_id) "Layer15_Attention_K_");
  auto Layer15_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer15_Attention_V,
      (const odla_value_id) "Layer15_Attention_V_");
  auto Layer15_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer15_Attention_Out,
      (const odla_value_id) "Layer15_Attention_Out_");
  auto Layer15_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer15_Attention_Out_Bias,
      (const odla_value_id) "Layer15_Attention_Out_Bias_");
  auto Layer15_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer15_Attention_Gamma,
      (const odla_value_id) "Layer15_Attention_Gamma_");
  auto Layer15_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer15_Attention_Beta,
      (const odla_value_id) "Layer15_Attention_Beta_");
  auto Layer15_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer15_FF_1_W,
      (const odla_value_id) "Layer15_FF_1_W_");
  auto Layer15_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer15_FF_1_B,
      (const odla_value_id) "Layer15_FF_1_B_");
  auto Layer15_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer15_FF_2_W,
      (const odla_value_id) "Layer15_FF_2_W_");
  auto Layer15_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer15_FF_2_B,
      (const odla_value_id) "Layer15_FF_2_B_");
  auto Layer15_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer15_FF_Gamma,
      (const odla_value_id) "Layer15_FF_Gamma_");
  auto Layer15_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer15_FF_Beta,
      (const odla_value_id) "Layer15_FF_Beta_");
  auto Layer16_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer16_Attention_Q,
      (const odla_value_id) "Layer16_Attention_Q_");
  auto Layer16_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer16_Attention_K,
      (const odla_value_id) "Layer16_Attention_K_");
  auto Layer16_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer16_Attention_V,
      (const odla_value_id) "Layer16_Attention_V_");
  auto Layer16_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer16_Attention_Out,
      (const odla_value_id) "Layer16_Attention_Out_");
  auto Layer16_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer16_Attention_Out_Bias,
      (const odla_value_id) "Layer16_Attention_Out_Bias_");
  auto Layer16_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer16_Attention_Gamma,
      (const odla_value_id) "Layer16_Attention_Gamma_");
  auto Layer16_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer16_Attention_Beta,
      (const odla_value_id) "Layer16_Attention_Beta_");
  auto Layer16_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer16_FF_1_W,
      (const odla_value_id) "Layer16_FF_1_W_");
  auto Layer16_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer16_FF_1_B,
      (const odla_value_id) "Layer16_FF_1_B_");
  auto Layer16_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer16_FF_2_W,
      (const odla_value_id) "Layer16_FF_2_W_");
  auto Layer16_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer16_FF_2_B,
      (const odla_value_id) "Layer16_FF_2_B_");
  auto Layer16_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer16_FF_Gamma,
      (const odla_value_id) "Layer16_FF_Gamma_");
  auto Layer16_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer16_FF_Beta,
      (const odla_value_id) "Layer16_FF_Beta_");
  auto Layer17_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer17_Attention_Q,
      (const odla_value_id) "Layer17_Attention_Q_");
  auto Layer17_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer17_Attention_K,
      (const odla_value_id) "Layer17_Attention_K_");
  auto Layer17_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer17_Attention_V,
      (const odla_value_id) "Layer17_Attention_V_");
  auto Layer17_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer17_Attention_Out,
      (const odla_value_id) "Layer17_Attention_Out_");
  auto Layer17_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer17_Attention_Out_Bias,
      (const odla_value_id) "Layer17_Attention_Out_Bias_");
  auto Layer17_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer17_Attention_Gamma,
      (const odla_value_id) "Layer17_Attention_Gamma_");
  auto Layer17_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer17_Attention_Beta,
      (const odla_value_id) "Layer17_Attention_Beta_");
  auto Layer17_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer17_FF_1_W,
      (const odla_value_id) "Layer17_FF_1_W_");
  auto Layer17_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer17_FF_1_B,
      (const odla_value_id) "Layer17_FF_1_B_");
  auto Layer17_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer17_FF_2_W,
      (const odla_value_id) "Layer17_FF_2_W_");
  auto Layer17_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer17_FF_2_B,
      (const odla_value_id) "Layer17_FF_2_B_");
  auto Layer17_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer17_FF_Gamma,
      (const odla_value_id) "Layer17_FF_Gamma_");
  auto Layer17_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer17_FF_Beta,
      (const odla_value_id) "Layer17_FF_Beta_");
  auto Layer18_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer18_Attention_Q,
      (const odla_value_id) "Layer18_Attention_Q_");
  auto Layer18_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer18_Attention_K,
      (const odla_value_id) "Layer18_Attention_K_");
  auto Layer18_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer18_Attention_V,
      (const odla_value_id) "Layer18_Attention_V_");
  auto Layer18_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer18_Attention_Out,
      (const odla_value_id) "Layer18_Attention_Out_");
  auto Layer18_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer18_Attention_Out_Bias,
      (const odla_value_id) "Layer18_Attention_Out_Bias_");
  auto Layer18_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer18_Attention_Gamma,
      (const odla_value_id) "Layer18_Attention_Gamma_");
  auto Layer18_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer18_Attention_Beta,
      (const odla_value_id) "Layer18_Attention_Beta_");
  auto Layer18_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer18_FF_1_W,
      (const odla_value_id) "Layer18_FF_1_W_");
  auto Layer18_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer18_FF_1_B,
      (const odla_value_id) "Layer18_FF_1_B_");
  auto Layer18_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer18_FF_2_W,
      (const odla_value_id) "Layer18_FF_2_W_");
  auto Layer18_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer18_FF_2_B,
      (const odla_value_id) "Layer18_FF_2_B_");
  auto Layer18_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer18_FF_Gamma,
      (const odla_value_id) "Layer18_FF_Gamma_");
  auto Layer18_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer18_FF_Beta,
      (const odla_value_id) "Layer18_FF_Beta_");
  auto Layer19_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer19_Attention_Q,
      (const odla_value_id) "Layer19_Attention_Q_");
  auto Layer19_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer19_Attention_K,
      (const odla_value_id) "Layer19_Attention_K_");
  auto Layer19_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer19_Attention_V,
      (const odla_value_id) "Layer19_Attention_V_");
  auto Layer19_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer19_Attention_Out,
      (const odla_value_id) "Layer19_Attention_Out_");
  auto Layer19_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer19_Attention_Out_Bias,
      (const odla_value_id) "Layer19_Attention_Out_Bias_");
  auto Layer19_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer19_Attention_Gamma,
      (const odla_value_id) "Layer19_Attention_Gamma_");
  auto Layer19_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer19_Attention_Beta,
      (const odla_value_id) "Layer19_Attention_Beta_");
  auto Layer19_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer19_FF_1_W,
      (const odla_value_id) "Layer19_FF_1_W_");
  auto Layer19_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer19_FF_1_B,
      (const odla_value_id) "Layer19_FF_1_B_");
  auto Layer19_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer19_FF_2_W,
      (const odla_value_id) "Layer19_FF_2_W_");
  auto Layer19_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer19_FF_2_B,
      (const odla_value_id) "Layer19_FF_2_B_");
  auto Layer19_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer19_FF_Gamma,
      (const odla_value_id) "Layer19_FF_Gamma_");
  auto Layer19_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer19_FF_Beta,
      (const odla_value_id) "Layer19_FF_Beta_");
  auto Layer20_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer20_Attention_Q,
      (const odla_value_id) "Layer20_Attention_Q_");
  auto Layer20_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer20_Attention_K,
      (const odla_value_id) "Layer20_Attention_K_");
  auto Layer20_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer20_Attention_V,
      (const odla_value_id) "Layer20_Attention_V_");
  auto Layer20_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer20_Attention_Out,
      (const odla_value_id) "Layer20_Attention_Out_");
  auto Layer20_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer20_Attention_Out_Bias,
      (const odla_value_id) "Layer20_Attention_Out_Bias_");
  auto Layer20_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer20_Attention_Gamma,
      (const odla_value_id) "Layer20_Attention_Gamma_");
  auto Layer20_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer20_Attention_Beta,
      (const odla_value_id) "Layer20_Attention_Beta_");
  auto Layer20_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer20_FF_1_W,
      (const odla_value_id) "Layer20_FF_1_W_");
  auto Layer20_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer20_FF_1_B,
      (const odla_value_id) "Layer20_FF_1_B_");
  auto Layer20_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer20_FF_2_W,
      (const odla_value_id) "Layer20_FF_2_W_");
  auto Layer20_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer20_FF_2_B,
      (const odla_value_id) "Layer20_FF_2_B_");
  auto Layer20_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer20_FF_Gamma,
      (const odla_value_id) "Layer20_FF_Gamma_");
  auto Layer20_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer20_FF_Beta,
      (const odla_value_id) "Layer20_FF_Beta_");
  auto Layer21_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer21_Attention_Q,
      (const odla_value_id) "Layer21_Attention_Q_");
  auto Layer21_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer21_Attention_K,
      (const odla_value_id) "Layer21_Attention_K_");
  auto Layer21_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer21_Attention_V,
      (const odla_value_id) "Layer21_Attention_V_");
  auto Layer21_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer21_Attention_Out,
      (const odla_value_id) "Layer21_Attention_Out_");
  auto Layer21_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer21_Attention_Out_Bias,
      (const odla_value_id) "Layer21_Attention_Out_Bias_");
  auto Layer21_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer21_Attention_Gamma,
      (const odla_value_id) "Layer21_Attention_Gamma_");
  auto Layer21_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer21_Attention_Beta,
      (const odla_value_id) "Layer21_Attention_Beta_");
  auto Layer21_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer21_FF_1_W,
      (const odla_value_id) "Layer21_FF_1_W_");
  auto Layer21_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer21_FF_1_B,
      (const odla_value_id) "Layer21_FF_1_B_");
  auto Layer21_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer21_FF_2_W,
      (const odla_value_id) "Layer21_FF_2_W_");
  auto Layer21_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer21_FF_2_B,
      (const odla_value_id) "Layer21_FF_2_B_");
  auto Layer21_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer21_FF_Gamma,
      (const odla_value_id) "Layer21_FF_Gamma_");
  auto Layer21_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer21_FF_Beta,
      (const odla_value_id) "Layer21_FF_Beta_");
  auto Layer22_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer22_Attention_Q,
      (const odla_value_id) "Layer22_Attention_Q_");
  auto Layer22_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer22_Attention_K,
      (const odla_value_id) "Layer22_Attention_K_");
  auto Layer22_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer22_Attention_V,
      (const odla_value_id) "Layer22_Attention_V_");
  auto Layer22_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer22_Attention_Out,
      (const odla_value_id) "Layer22_Attention_Out_");
  auto Layer22_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer22_Attention_Out_Bias,
      (const odla_value_id) "Layer22_Attention_Out_Bias_");
  auto Layer22_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer22_Attention_Gamma,
      (const odla_value_id) "Layer22_Attention_Gamma_");
  auto Layer22_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer22_Attention_Beta,
      (const odla_value_id) "Layer22_Attention_Beta_");
  auto Layer22_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer22_FF_1_W,
      (const odla_value_id) "Layer22_FF_1_W_");
  auto Layer22_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer22_FF_1_B,
      (const odla_value_id) "Layer22_FF_1_B_");
  auto Layer22_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer22_FF_2_W,
      (const odla_value_id) "Layer22_FF_2_W_");
  auto Layer22_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer22_FF_2_B,
      (const odla_value_id) "Layer22_FF_2_B_");
  auto Layer22_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer22_FF_Gamma,
      (const odla_value_id) "Layer22_FF_Gamma_");
  auto Layer22_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer22_FF_Beta,
      (const odla_value_id) "Layer22_FF_Beta_");
  auto Layer23_Attention_Q_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer23_Attention_Q,
      (const odla_value_id) "Layer23_Attention_Q_");
  auto Layer23_Attention_K_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer23_Attention_K,
      (const odla_value_id) "Layer23_Attention_K_");
  auto Layer23_Attention_V_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer23_Attention_V,
      (const odla_value_id) "Layer23_Attention_V_");
  auto Layer23_Attention_Out_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 1024}}}, Layer23_Attention_Out,
      (const odla_value_id) "Layer23_Attention_Out_");
  auto Layer23_Attention_Out_Bias_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer23_Attention_Out_Bias,
      (const odla_value_id) "Layer23_Attention_Out_Bias_");
  auto Layer23_Attention_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer23_Attention_Gamma,
      (const odla_value_id) "Layer23_Attention_Gamma_");
  auto Layer23_Attention_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer23_Attention_Beta,
      (const odla_value_id) "Layer23_Attention_Beta_");
  auto Layer23_FF_1_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {1024, 4096}}}, Layer23_FF_1_W,
      (const odla_value_id) "Layer23_FF_1_W_");
  auto Layer23_FF_1_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {4096}}}, Layer23_FF_1_B,
      (const odla_value_id) "Layer23_FF_1_B_");
  auto Layer23_FF_2_W_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 2, .dims = {4096, 1024}}}, Layer23_FF_2_W,
      (const odla_value_id) "Layer23_FF_2_W_");
  auto Layer23_FF_2_B_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer23_FF_2_B,
      (const odla_value_id) "Layer23_FF_2_B_");
  auto Layer23_FF_Gamma_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer23_FF_Gamma,
      (const odla_value_id) "Layer23_FF_Gamma_");
  auto Layer23_FF_Beta_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {1024}}}, Layer23_FF_Beta,
      (const odla_value_id) "Layer23_FF_Beta_");
  auto Squad_SquadW_ =
      odla_CreateConstant({ODLA_FLOAT16, {.size = 2, .dims = {1024, 2}}},
                          Squad_SquadW, (const odla_value_id) "Squad_SquadW_");
  auto Squad_SquadB_ =
      odla_CreateConstant({ODLA_FLOAT16, {.size = 1, .dims = {2}}},
                          Squad_SquadB, (const odla_value_id) "Squad_SquadB_");
  auto Embedding_Constant_0_ = odla_CreateConstant(
      {ODLA_INT32, {.size = 0, .dims = {}}}, Embedding_Constant_0,
      (const odla_value_id) "Embedding_Constant_0_");
  auto Embedding_Constant_0_1_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 1, .dims = {2}}}, Embedding_Constant_0_1,
      (const odla_value_id) "Embedding_Constant_0_1_");
  auto Embedding_OneHot_on_value_ = odla_CreateConstant(
      {ODLA_FLOAT16, {.size = 0, .dims = {}}}, Embedding_OneHot_on_value,
      (const odla_value_id) "Embedding_OneHot_on_value_");
  auto Embedding_Gather = odla_Gather(Embedding_Embedding_Dict_, indices, 0,
                                      {.size = 2, .dims = {3840, 1024}},
                                      (const odla_value_id) "Embedding_Gather");
  auto Embedding_OneHot = odla_OneHot(segments, 2, Embedding_Constant_0_1_, -1,
                                      {.size = 2, .dims = {3840, 2}},
                                      (const odla_value_id) "Embedding_OneHot");
  auto Embedding_MatMul =
      odla_Gemm(Embedding_OneHot, 0, Embedding_Segment_Dict_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Embedding_MatMul");
  auto Embedding_Gather_1 =
      odla_Gather(Embedding_Positional_Dict_, positions, 0,
                  {.size = 2, .dims = {3840, 1024}},
                  (const odla_value_id) "Embedding_Gather_1");
  auto Embedding_Add = odla_Add(Embedding_Gather, Embedding_Gather_1,
                                (const odla_value_id) "Embedding_Add");
  auto Embedding_Add_1 = odla_Add(Embedding_Add, Embedding_MatMul,
                                  (const odla_value_id) "Embedding_Add_1");
  auto Embedding_GroupNormalization = odla_GroupNormalization(
      Embedding_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Embedding_Gamma_, Embedding_Beta_, 1, 0,
      (const odla_value_id) "Embedding_GroupNormalization");
  auto Layer0_Attention_MatMul =
      odla_Gemm(Embedding_GroupNormalization, 0, Layer0_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer0_Attention_MatMul");
  auto Layer0_Attention_MatMul_1 =
      odla_Gemm(Embedding_GroupNormalization, 0, Layer0_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer0_Attention_MatMul_1");
  auto Layer0_Attention_MatMul_2 =
      odla_Gemm(Embedding_GroupNormalization, 0, Layer0_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer0_Attention_MatMul_2");
  auto Layer0_Attention_Reshape = odla_Reshape(
      Layer0_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer0_Attention_Reshape");
  auto Layer0_Attention_Transpose = odla_Transpose(
      Layer0_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer0_Attention_Transpose");
  auto Layer0_Attention_Reshape_1 = odla_Reshape(
      Layer0_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer0_Attention_Reshape_1");
  auto Layer0_Attention_Transpose_1 = odla_Transpose(
      Layer0_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer0_Attention_Transpose_1");
  auto Layer0_Attention_Reshape_2 = odla_Reshape(
      Layer0_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer0_Attention_Reshape_2");
  auto Layer0_Attention_Transpose_2 = odla_Transpose(
      Layer0_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer0_Attention_Transpose_2");
  auto Layer0_Attention_Z_MatMul =
      odla_Gemm(Layer0_Attention_Transpose, 0, Layer0_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer0_Attention_Z_MatMul");
  auto Layer0_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer0_Attention_Z_Mask_Reshape");
  auto Layer0_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer0_Attention_Z_Mask_Reshape,
                            Layer0_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer0_Attention_Z_Mask_AttentionMask0"}});
  auto Layer0_Attention_Z_Mask_AttentionMask0 =
      Layer0_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer0_Attention_Z_ApplyMask = odla_Add(
      Layer0_Attention_Z_MatMul, Layer0_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer0_Attention_Z_ApplyMask");
  auto Layer0_Attention_Z_Softmax =
      odla_Softmax(Layer0_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer0_Attention_Z_Softmax");
  auto Layer0_Attention_Z_MatMul_1 =
      odla_Gemm(Layer0_Attention_Z_Softmax, 0, Layer0_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer0_Attention_Z_MatMul_1");
  auto Layer0_Attention_Z_Transpose = odla_Transpose(
      Layer0_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer0_Attention_Z_Transpose");
  auto Layer0_Attention_Z_Reshape = odla_Reshape(
      Layer0_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer0_Attention_Z_Reshape");
  auto Layer0_Attention_MatMul_3 =
      odla_Gemm(Layer0_Attention_Z_Reshape, 0, Layer0_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer0_Attention_MatMul_3");
  auto Layer0_Attention_Add =
      odla_Add(Layer0_Attention_MatMul_3, Layer0_Attention_Out_Bias_,
               (const odla_value_id) "Layer0_Attention_Add");
  auto Layer0_Attention_Add_1 =
      odla_Add(Embedding_GroupNormalization, Layer0_Attention_Add,
               (const odla_value_id) "Layer0_Attention_Add_1");
  auto Layer0_Attention_GroupNormalization = odla_GroupNormalization(
      Layer0_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer0_Attention_Gamma_, Layer0_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer0_Attention_GroupNormalization");
  auto Layer0_FF_1_MatMul =
      odla_Gemm(Layer0_Attention_GroupNormalization, 0, Layer0_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer0_FF_1_MatMul");
  auto Layer0_FF_1_Add = odla_Add(Layer0_FF_1_MatMul, Layer0_FF_1_B_,
                                  (const odla_value_id) "Layer0_FF_1_Add");
  auto Layer0_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer0_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer0_FF_Gelu0"}});
  auto Layer0_FF_Gelu0 = Layer0_FF_Gelu0_array.values[0];
  auto Layer0_FF_2_MatMul =
      odla_Gemm(Layer0_FF_Gelu0, 0, Layer0_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer0_FF_2_MatMul");
  auto Layer0_FF_2_Add = odla_Add(Layer0_FF_2_MatMul, Layer0_FF_2_B_,
                                  (const odla_value_id) "Layer0_FF_2_Add");
  auto Layer0_FF_Add =
      odla_Add(Layer0_Attention_GroupNormalization, Layer0_FF_2_Add,
               (const odla_value_id) "Layer0_FF_Add");
  auto Layer0_FF_GroupNormalization = odla_GroupNormalization(
      Layer0_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer0_FF_Gamma_, Layer0_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer0_FF_GroupNormalization");
  auto Layer1_Attention_MatMul =
      odla_Gemm(Layer0_FF_GroupNormalization, 0, Layer1_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer1_Attention_MatMul");
  auto Layer1_Attention_MatMul_1 =
      odla_Gemm(Layer0_FF_GroupNormalization, 0, Layer1_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer1_Attention_MatMul_1");
  auto Layer1_Attention_MatMul_2 =
      odla_Gemm(Layer0_FF_GroupNormalization, 0, Layer1_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer1_Attention_MatMul_2");
  auto Layer1_Attention_Reshape = odla_Reshape(
      Layer1_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer1_Attention_Reshape");
  auto Layer1_Attention_Transpose = odla_Transpose(
      Layer1_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer1_Attention_Transpose");
  auto Layer1_Attention_Reshape_1 = odla_Reshape(
      Layer1_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer1_Attention_Reshape_1");
  auto Layer1_Attention_Transpose_1 = odla_Transpose(
      Layer1_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer1_Attention_Transpose_1");
  auto Layer1_Attention_Reshape_2 = odla_Reshape(
      Layer1_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer1_Attention_Reshape_2");
  auto Layer1_Attention_Transpose_2 = odla_Transpose(
      Layer1_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer1_Attention_Transpose_2");
  auto Layer1_Attention_Z_MatMul =
      odla_Gemm(Layer1_Attention_Transpose, 0, Layer1_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer1_Attention_Z_MatMul");
  auto Layer1_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer1_Attention_Z_Mask_Reshape");
  auto Layer1_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer1_Attention_Z_Mask_Reshape,
                            Layer1_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer1_Attention_Z_Mask_AttentionMask0"}});
  auto Layer1_Attention_Z_Mask_AttentionMask0 =
      Layer1_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer1_Attention_Z_ApplyMask = odla_Add(
      Layer1_Attention_Z_MatMul, Layer1_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer1_Attention_Z_ApplyMask");
  auto Layer1_Attention_Z_Softmax =
      odla_Softmax(Layer1_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer1_Attention_Z_Softmax");
  auto Layer1_Attention_Z_MatMul_1 =
      odla_Gemm(Layer1_Attention_Z_Softmax, 0, Layer1_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer1_Attention_Z_MatMul_1");
  auto Layer1_Attention_Z_Transpose = odla_Transpose(
      Layer1_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer1_Attention_Z_Transpose");
  auto Layer1_Attention_Z_Reshape = odla_Reshape(
      Layer1_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer1_Attention_Z_Reshape");
  auto Layer1_Attention_MatMul_3 =
      odla_Gemm(Layer1_Attention_Z_Reshape, 0, Layer1_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer1_Attention_MatMul_3");
  auto Layer1_Attention_Add =
      odla_Add(Layer1_Attention_MatMul_3, Layer1_Attention_Out_Bias_,
               (const odla_value_id) "Layer1_Attention_Add");
  auto Layer1_Attention_Add_1 =
      odla_Add(Layer0_FF_GroupNormalization, Layer1_Attention_Add,
               (const odla_value_id) "Layer1_Attention_Add_1");
  auto Layer1_Attention_GroupNormalization = odla_GroupNormalization(
      Layer1_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer1_Attention_Gamma_, Layer1_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer1_Attention_GroupNormalization");
  auto Layer1_FF_1_MatMul =
      odla_Gemm(Layer1_Attention_GroupNormalization, 0, Layer1_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer1_FF_1_MatMul");
  auto Layer1_FF_1_Add = odla_Add(Layer1_FF_1_MatMul, Layer1_FF_1_B_,
                                  (const odla_value_id) "Layer1_FF_1_Add");
  auto Layer1_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer1_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer1_FF_Gelu0"}});
  auto Layer1_FF_Gelu0 = Layer1_FF_Gelu0_array.values[0];
  auto Layer1_FF_2_MatMul =
      odla_Gemm(Layer1_FF_Gelu0, 0, Layer1_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer1_FF_2_MatMul");
  auto Layer1_FF_2_Add = odla_Add(Layer1_FF_2_MatMul, Layer1_FF_2_B_,
                                  (const odla_value_id) "Layer1_FF_2_Add");
  auto Layer1_FF_Add =
      odla_Add(Layer1_Attention_GroupNormalization, Layer1_FF_2_Add,
               (const odla_value_id) "Layer1_FF_Add");
  auto Layer1_FF_GroupNormalization = odla_GroupNormalization(
      Layer1_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer1_FF_Gamma_, Layer1_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer1_FF_GroupNormalization");
  auto Layer2_Attention_MatMul =
      odla_Gemm(Layer1_FF_GroupNormalization, 0, Layer2_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer2_Attention_MatMul");
  auto Layer2_Attention_MatMul_1 =
      odla_Gemm(Layer1_FF_GroupNormalization, 0, Layer2_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer2_Attention_MatMul_1");
  auto Layer2_Attention_MatMul_2 =
      odla_Gemm(Layer1_FF_GroupNormalization, 0, Layer2_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer2_Attention_MatMul_2");
  auto Layer2_Attention_Reshape = odla_Reshape(
      Layer2_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer2_Attention_Reshape");
  auto Layer2_Attention_Transpose = odla_Transpose(
      Layer2_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer2_Attention_Transpose");
  auto Layer2_Attention_Reshape_1 = odla_Reshape(
      Layer2_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer2_Attention_Reshape_1");
  auto Layer2_Attention_Transpose_1 = odla_Transpose(
      Layer2_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer2_Attention_Transpose_1");
  auto Layer2_Attention_Reshape_2 = odla_Reshape(
      Layer2_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer2_Attention_Reshape_2");
  auto Layer2_Attention_Transpose_2 = odla_Transpose(
      Layer2_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer2_Attention_Transpose_2");
  auto Layer2_Attention_Z_MatMul =
      odla_Gemm(Layer2_Attention_Transpose, 0, Layer2_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer2_Attention_Z_MatMul");
  auto Layer2_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer2_Attention_Z_Mask_Reshape");
  auto Layer2_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer2_Attention_Z_Mask_Reshape,
                            Layer2_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer2_Attention_Z_Mask_AttentionMask0"}});
  auto Layer2_Attention_Z_Mask_AttentionMask0 =
      Layer2_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer2_Attention_Z_ApplyMask = odla_Add(
      Layer2_Attention_Z_MatMul, Layer2_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer2_Attention_Z_ApplyMask");
  auto Layer2_Attention_Z_Softmax =
      odla_Softmax(Layer2_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer2_Attention_Z_Softmax");
  auto Layer2_Attention_Z_MatMul_1 =
      odla_Gemm(Layer2_Attention_Z_Softmax, 0, Layer2_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer2_Attention_Z_MatMul_1");
  auto Layer2_Attention_Z_Transpose = odla_Transpose(
      Layer2_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer2_Attention_Z_Transpose");
  auto Layer2_Attention_Z_Reshape = odla_Reshape(
      Layer2_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer2_Attention_Z_Reshape");
  auto Layer2_Attention_MatMul_3 =
      odla_Gemm(Layer2_Attention_Z_Reshape, 0, Layer2_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer2_Attention_MatMul_3");
  auto Layer2_Attention_Add =
      odla_Add(Layer2_Attention_MatMul_3, Layer2_Attention_Out_Bias_,
               (const odla_value_id) "Layer2_Attention_Add");
  auto Layer2_Attention_Add_1 =
      odla_Add(Layer1_FF_GroupNormalization, Layer2_Attention_Add,
               (const odla_value_id) "Layer2_Attention_Add_1");
  auto Layer2_Attention_GroupNormalization = odla_GroupNormalization(
      Layer2_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer2_Attention_Gamma_, Layer2_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer2_Attention_GroupNormalization");
  auto Layer2_FF_1_MatMul =
      odla_Gemm(Layer2_Attention_GroupNormalization, 0, Layer2_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer2_FF_1_MatMul");
  auto Layer2_FF_1_Add = odla_Add(Layer2_FF_1_MatMul, Layer2_FF_1_B_,
                                  (const odla_value_id) "Layer2_FF_1_Add");
  auto Layer2_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer2_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer2_FF_Gelu0"}});
  auto Layer2_FF_Gelu0 = Layer2_FF_Gelu0_array.values[0];
  auto Layer2_FF_2_MatMul =
      odla_Gemm(Layer2_FF_Gelu0, 0, Layer2_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer2_FF_2_MatMul");
  auto Layer2_FF_2_Add = odla_Add(Layer2_FF_2_MatMul, Layer2_FF_2_B_,
                                  (const odla_value_id) "Layer2_FF_2_Add");
  auto Layer2_FF_Add =
      odla_Add(Layer2_Attention_GroupNormalization, Layer2_FF_2_Add,
               (const odla_value_id) "Layer2_FF_Add");
  auto Layer2_FF_GroupNormalization = odla_GroupNormalization(
      Layer2_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer2_FF_Gamma_, Layer2_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer2_FF_GroupNormalization");
  auto Layer3_Attention_MatMul =
      odla_Gemm(Layer2_FF_GroupNormalization, 0, Layer3_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer3_Attention_MatMul");
  auto Layer3_Attention_MatMul_1 =
      odla_Gemm(Layer2_FF_GroupNormalization, 0, Layer3_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer3_Attention_MatMul_1");
  auto Layer3_Attention_MatMul_2 =
      odla_Gemm(Layer2_FF_GroupNormalization, 0, Layer3_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer3_Attention_MatMul_2");
  auto Layer3_Attention_Reshape = odla_Reshape(
      Layer3_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer3_Attention_Reshape");
  auto Layer3_Attention_Transpose = odla_Transpose(
      Layer3_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer3_Attention_Transpose");
  auto Layer3_Attention_Reshape_1 = odla_Reshape(
      Layer3_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer3_Attention_Reshape_1");
  auto Layer3_Attention_Transpose_1 = odla_Transpose(
      Layer3_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer3_Attention_Transpose_1");
  auto Layer3_Attention_Reshape_2 = odla_Reshape(
      Layer3_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer3_Attention_Reshape_2");
  auto Layer3_Attention_Transpose_2 = odla_Transpose(
      Layer3_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer3_Attention_Transpose_2");
  auto Layer3_Attention_Z_MatMul =
      odla_Gemm(Layer3_Attention_Transpose, 0, Layer3_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer3_Attention_Z_MatMul");
  auto Layer3_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer3_Attention_Z_Mask_Reshape");
  auto Layer3_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer3_Attention_Z_Mask_Reshape,
                            Layer3_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer3_Attention_Z_Mask_AttentionMask0"}});
  auto Layer3_Attention_Z_Mask_AttentionMask0 =
      Layer3_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer3_Attention_Z_ApplyMask = odla_Add(
      Layer3_Attention_Z_MatMul, Layer3_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer3_Attention_Z_ApplyMask");
  auto Layer3_Attention_Z_Softmax =
      odla_Softmax(Layer3_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer3_Attention_Z_Softmax");
  auto Layer3_Attention_Z_MatMul_1 =
      odla_Gemm(Layer3_Attention_Z_Softmax, 0, Layer3_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer3_Attention_Z_MatMul_1");
  auto Layer3_Attention_Z_Transpose = odla_Transpose(
      Layer3_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer3_Attention_Z_Transpose");
  auto Layer3_Attention_Z_Reshape = odla_Reshape(
      Layer3_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer3_Attention_Z_Reshape");
  auto Layer3_Attention_MatMul_3 =
      odla_Gemm(Layer3_Attention_Z_Reshape, 0, Layer3_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer3_Attention_MatMul_3");
  auto Layer3_Attention_Add =
      odla_Add(Layer3_Attention_MatMul_3, Layer3_Attention_Out_Bias_,
               (const odla_value_id) "Layer3_Attention_Add");
  auto Layer3_Attention_Add_1 =
      odla_Add(Layer2_FF_GroupNormalization, Layer3_Attention_Add,
               (const odla_value_id) "Layer3_Attention_Add_1");
  auto Layer3_Attention_GroupNormalization = odla_GroupNormalization(
      Layer3_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer3_Attention_Gamma_, Layer3_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer3_Attention_GroupNormalization");
  auto Layer3_FF_1_MatMul =
      odla_Gemm(Layer3_Attention_GroupNormalization, 0, Layer3_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer3_FF_1_MatMul");
  auto Layer3_FF_1_Add = odla_Add(Layer3_FF_1_MatMul, Layer3_FF_1_B_,
                                  (const odla_value_id) "Layer3_FF_1_Add");
  auto Layer3_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer3_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer3_FF_Gelu0"}});
  auto Layer3_FF_Gelu0 = Layer3_FF_Gelu0_array.values[0];
  auto Layer3_FF_2_MatMul =
      odla_Gemm(Layer3_FF_Gelu0, 0, Layer3_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer3_FF_2_MatMul");
  auto Layer3_FF_2_Add = odla_Add(Layer3_FF_2_MatMul, Layer3_FF_2_B_,
                                  (const odla_value_id) "Layer3_FF_2_Add");
  auto Layer3_FF_Add =
      odla_Add(Layer3_Attention_GroupNormalization, Layer3_FF_2_Add,
               (const odla_value_id) "Layer3_FF_Add");
  auto Layer3_FF_GroupNormalization = odla_GroupNormalization(
      Layer3_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer3_FF_Gamma_, Layer3_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer3_FF_GroupNormalization");
  auto Layer4_Attention_MatMul =
      odla_Gemm(Layer3_FF_GroupNormalization, 0, Layer4_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer4_Attention_MatMul");
  auto Layer4_Attention_MatMul_1 =
      odla_Gemm(Layer3_FF_GroupNormalization, 0, Layer4_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer4_Attention_MatMul_1");
  auto Layer4_Attention_MatMul_2 =
      odla_Gemm(Layer3_FF_GroupNormalization, 0, Layer4_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer4_Attention_MatMul_2");
  auto Layer4_Attention_Reshape = odla_Reshape(
      Layer4_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer4_Attention_Reshape");
  auto Layer4_Attention_Transpose = odla_Transpose(
      Layer4_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer4_Attention_Transpose");
  auto Layer4_Attention_Reshape_1 = odla_Reshape(
      Layer4_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer4_Attention_Reshape_1");
  auto Layer4_Attention_Transpose_1 = odla_Transpose(
      Layer4_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer4_Attention_Transpose_1");
  auto Layer4_Attention_Reshape_2 = odla_Reshape(
      Layer4_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer4_Attention_Reshape_2");
  auto Layer4_Attention_Transpose_2 = odla_Transpose(
      Layer4_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer4_Attention_Transpose_2");
  auto Layer4_Attention_Z_MatMul =
      odla_Gemm(Layer4_Attention_Transpose, 0, Layer4_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer4_Attention_Z_MatMul");
  auto Layer4_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer4_Attention_Z_Mask_Reshape");
  auto Layer4_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer4_Attention_Z_Mask_Reshape,
                            Layer4_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer4_Attention_Z_Mask_AttentionMask0"}});
  auto Layer4_Attention_Z_Mask_AttentionMask0 =
      Layer4_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer4_Attention_Z_ApplyMask = odla_Add(
      Layer4_Attention_Z_MatMul, Layer4_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer4_Attention_Z_ApplyMask");
  auto Layer4_Attention_Z_Softmax =
      odla_Softmax(Layer4_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer4_Attention_Z_Softmax");
  auto Layer4_Attention_Z_MatMul_1 =
      odla_Gemm(Layer4_Attention_Z_Softmax, 0, Layer4_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer4_Attention_Z_MatMul_1");
  auto Layer4_Attention_Z_Transpose = odla_Transpose(
      Layer4_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer4_Attention_Z_Transpose");
  auto Layer4_Attention_Z_Reshape = odla_Reshape(
      Layer4_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer4_Attention_Z_Reshape");
  auto Layer4_Attention_MatMul_3 =
      odla_Gemm(Layer4_Attention_Z_Reshape, 0, Layer4_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer4_Attention_MatMul_3");
  auto Layer4_Attention_Add =
      odla_Add(Layer4_Attention_MatMul_3, Layer4_Attention_Out_Bias_,
               (const odla_value_id) "Layer4_Attention_Add");
  auto Layer4_Attention_Add_1 =
      odla_Add(Layer3_FF_GroupNormalization, Layer4_Attention_Add,
               (const odla_value_id) "Layer4_Attention_Add_1");
  auto Layer4_Attention_GroupNormalization = odla_GroupNormalization(
      Layer4_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer4_Attention_Gamma_, Layer4_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer4_Attention_GroupNormalization");
  auto Layer4_FF_1_MatMul =
      odla_Gemm(Layer4_Attention_GroupNormalization, 0, Layer4_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer4_FF_1_MatMul");
  auto Layer4_FF_1_Add = odla_Add(Layer4_FF_1_MatMul, Layer4_FF_1_B_,
                                  (const odla_value_id) "Layer4_FF_1_Add");
  auto Layer4_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer4_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer4_FF_Gelu0"}});
  auto Layer4_FF_Gelu0 = Layer4_FF_Gelu0_array.values[0];
  auto Layer4_FF_2_MatMul =
      odla_Gemm(Layer4_FF_Gelu0, 0, Layer4_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer4_FF_2_MatMul");
  auto Layer4_FF_2_Add = odla_Add(Layer4_FF_2_MatMul, Layer4_FF_2_B_,
                                  (const odla_value_id) "Layer4_FF_2_Add");
  auto Layer4_FF_Add =
      odla_Add(Layer4_Attention_GroupNormalization, Layer4_FF_2_Add,
               (const odla_value_id) "Layer4_FF_Add");
  auto Layer4_FF_GroupNormalization = odla_GroupNormalization(
      Layer4_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer4_FF_Gamma_, Layer4_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer4_FF_GroupNormalization");
  auto Layer5_Attention_MatMul =
      odla_Gemm(Layer4_FF_GroupNormalization, 0, Layer5_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer5_Attention_MatMul");
  auto Layer5_Attention_MatMul_1 =
      odla_Gemm(Layer4_FF_GroupNormalization, 0, Layer5_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer5_Attention_MatMul_1");
  auto Layer5_Attention_MatMul_2 =
      odla_Gemm(Layer4_FF_GroupNormalization, 0, Layer5_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer5_Attention_MatMul_2");
  auto Layer5_Attention_Reshape = odla_Reshape(
      Layer5_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer5_Attention_Reshape");
  auto Layer5_Attention_Transpose = odla_Transpose(
      Layer5_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer5_Attention_Transpose");
  auto Layer5_Attention_Reshape_1 = odla_Reshape(
      Layer5_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer5_Attention_Reshape_1");
  auto Layer5_Attention_Transpose_1 = odla_Transpose(
      Layer5_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer5_Attention_Transpose_1");
  auto Layer5_Attention_Reshape_2 = odla_Reshape(
      Layer5_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer5_Attention_Reshape_2");
  auto Layer5_Attention_Transpose_2 = odla_Transpose(
      Layer5_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer5_Attention_Transpose_2");
  auto Layer5_Attention_Z_MatMul =
      odla_Gemm(Layer5_Attention_Transpose, 0, Layer5_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer5_Attention_Z_MatMul");
  auto Layer5_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer5_Attention_Z_Mask_Reshape");
  auto Layer5_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer5_Attention_Z_Mask_Reshape,
                            Layer5_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer5_Attention_Z_Mask_AttentionMask0"}});
  auto Layer5_Attention_Z_Mask_AttentionMask0 =
      Layer5_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer5_Attention_Z_ApplyMask = odla_Add(
      Layer5_Attention_Z_MatMul, Layer5_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer5_Attention_Z_ApplyMask");
  auto Layer5_Attention_Z_Softmax =
      odla_Softmax(Layer5_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer5_Attention_Z_Softmax");
  auto Layer5_Attention_Z_MatMul_1 =
      odla_Gemm(Layer5_Attention_Z_Softmax, 0, Layer5_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer5_Attention_Z_MatMul_1");
  auto Layer5_Attention_Z_Transpose = odla_Transpose(
      Layer5_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer5_Attention_Z_Transpose");
  auto Layer5_Attention_Z_Reshape = odla_Reshape(
      Layer5_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer5_Attention_Z_Reshape");
  auto Layer5_Attention_MatMul_3 =
      odla_Gemm(Layer5_Attention_Z_Reshape, 0, Layer5_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer5_Attention_MatMul_3");
  auto Layer5_Attention_Add =
      odla_Add(Layer5_Attention_MatMul_3, Layer5_Attention_Out_Bias_,
               (const odla_value_id) "Layer5_Attention_Add");
  auto Layer5_Attention_Add_1 =
      odla_Add(Layer4_FF_GroupNormalization, Layer5_Attention_Add,
               (const odla_value_id) "Layer5_Attention_Add_1");
  auto Layer5_Attention_GroupNormalization = odla_GroupNormalization(
      Layer5_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer5_Attention_Gamma_, Layer5_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer5_Attention_GroupNormalization");
  auto Layer5_FF_1_MatMul =
      odla_Gemm(Layer5_Attention_GroupNormalization, 0, Layer5_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer5_FF_1_MatMul");
  auto Layer5_FF_1_Add = odla_Add(Layer5_FF_1_MatMul, Layer5_FF_1_B_,
                                  (const odla_value_id) "Layer5_FF_1_Add");
  auto Layer5_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer5_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer5_FF_Gelu0"}});
  auto Layer5_FF_Gelu0 = Layer5_FF_Gelu0_array.values[0];
  auto Layer5_FF_2_MatMul =
      odla_Gemm(Layer5_FF_Gelu0, 0, Layer5_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer5_FF_2_MatMul");
  auto Layer5_FF_2_Add = odla_Add(Layer5_FF_2_MatMul, Layer5_FF_2_B_,
                                  (const odla_value_id) "Layer5_FF_2_Add");
  auto Layer5_FF_Add =
      odla_Add(Layer5_Attention_GroupNormalization, Layer5_FF_2_Add,
               (const odla_value_id) "Layer5_FF_Add");
  auto Layer5_FF_GroupNormalization = odla_GroupNormalization(
      Layer5_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer5_FF_Gamma_, Layer5_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer5_FF_GroupNormalization");
  auto Layer6_Attention_MatMul =
      odla_Gemm(Layer5_FF_GroupNormalization, 0, Layer6_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer6_Attention_MatMul");
  auto Layer6_Attention_MatMul_1 =
      odla_Gemm(Layer5_FF_GroupNormalization, 0, Layer6_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer6_Attention_MatMul_1");
  auto Layer6_Attention_MatMul_2 =
      odla_Gemm(Layer5_FF_GroupNormalization, 0, Layer6_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer6_Attention_MatMul_2");
  auto Layer6_Attention_Reshape = odla_Reshape(
      Layer6_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer6_Attention_Reshape");
  auto Layer6_Attention_Transpose = odla_Transpose(
      Layer6_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer6_Attention_Transpose");
  auto Layer6_Attention_Reshape_1 = odla_Reshape(
      Layer6_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer6_Attention_Reshape_1");
  auto Layer6_Attention_Transpose_1 = odla_Transpose(
      Layer6_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer6_Attention_Transpose_1");
  auto Layer6_Attention_Reshape_2 = odla_Reshape(
      Layer6_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer6_Attention_Reshape_2");
  auto Layer6_Attention_Transpose_2 = odla_Transpose(
      Layer6_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer6_Attention_Transpose_2");
  auto Layer6_Attention_Z_MatMul =
      odla_Gemm(Layer6_Attention_Transpose, 0, Layer6_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer6_Attention_Z_MatMul");
  auto Layer6_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer6_Attention_Z_Mask_Reshape");
  auto Layer6_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer6_Attention_Z_Mask_Reshape,
                            Layer6_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer6_Attention_Z_Mask_AttentionMask0"}});
  auto Layer6_Attention_Z_Mask_AttentionMask0 =
      Layer6_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer6_Attention_Z_ApplyMask = odla_Add(
      Layer6_Attention_Z_MatMul, Layer6_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer6_Attention_Z_ApplyMask");
  auto Layer6_Attention_Z_Softmax =
      odla_Softmax(Layer6_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer6_Attention_Z_Softmax");
  auto Layer6_Attention_Z_MatMul_1 =
      odla_Gemm(Layer6_Attention_Z_Softmax, 0, Layer6_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer6_Attention_Z_MatMul_1");
  auto Layer6_Attention_Z_Transpose = odla_Transpose(
      Layer6_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer6_Attention_Z_Transpose");
  auto Layer6_Attention_Z_Reshape = odla_Reshape(
      Layer6_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer6_Attention_Z_Reshape");
  auto Layer6_Attention_MatMul_3 =
      odla_Gemm(Layer6_Attention_Z_Reshape, 0, Layer6_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer6_Attention_MatMul_3");
  auto Layer6_Attention_Add =
      odla_Add(Layer6_Attention_MatMul_3, Layer6_Attention_Out_Bias_,
               (const odla_value_id) "Layer6_Attention_Add");
  auto Layer6_Attention_Add_1 =
      odla_Add(Layer5_FF_GroupNormalization, Layer6_Attention_Add,
               (const odla_value_id) "Layer6_Attention_Add_1");
  auto Layer6_Attention_GroupNormalization = odla_GroupNormalization(
      Layer6_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer6_Attention_Gamma_, Layer6_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer6_Attention_GroupNormalization");
  auto Layer6_FF_1_MatMul =
      odla_Gemm(Layer6_Attention_GroupNormalization, 0, Layer6_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer6_FF_1_MatMul");
  auto Layer6_FF_1_Add = odla_Add(Layer6_FF_1_MatMul, Layer6_FF_1_B_,
                                  (const odla_value_id) "Layer6_FF_1_Add");
  auto Layer6_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer6_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer6_FF_Gelu0"}});
  auto Layer6_FF_Gelu0 = Layer6_FF_Gelu0_array.values[0];
  auto Layer6_FF_2_MatMul =
      odla_Gemm(Layer6_FF_Gelu0, 0, Layer6_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer6_FF_2_MatMul");
  auto Layer6_FF_2_Add = odla_Add(Layer6_FF_2_MatMul, Layer6_FF_2_B_,
                                  (const odla_value_id) "Layer6_FF_2_Add");
  auto Layer6_FF_Add =
      odla_Add(Layer6_Attention_GroupNormalization, Layer6_FF_2_Add,
               (const odla_value_id) "Layer6_FF_Add");
  auto Layer6_FF_GroupNormalization = odla_GroupNormalization(
      Layer6_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer6_FF_Gamma_, Layer6_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer6_FF_GroupNormalization");
  auto Layer7_Attention_MatMul =
      odla_Gemm(Layer6_FF_GroupNormalization, 0, Layer7_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer7_Attention_MatMul");
  auto Layer7_Attention_MatMul_1 =
      odla_Gemm(Layer6_FF_GroupNormalization, 0, Layer7_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer7_Attention_MatMul_1");
  auto Layer7_Attention_MatMul_2 =
      odla_Gemm(Layer6_FF_GroupNormalization, 0, Layer7_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer7_Attention_MatMul_2");
  auto Layer7_Attention_Reshape = odla_Reshape(
      Layer7_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer7_Attention_Reshape");
  auto Layer7_Attention_Transpose = odla_Transpose(
      Layer7_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer7_Attention_Transpose");
  auto Layer7_Attention_Reshape_1 = odla_Reshape(
      Layer7_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer7_Attention_Reshape_1");
  auto Layer7_Attention_Transpose_1 = odla_Transpose(
      Layer7_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer7_Attention_Transpose_1");
  auto Layer7_Attention_Reshape_2 = odla_Reshape(
      Layer7_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer7_Attention_Reshape_2");
  auto Layer7_Attention_Transpose_2 = odla_Transpose(
      Layer7_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer7_Attention_Transpose_2");
  auto Layer7_Attention_Z_MatMul =
      odla_Gemm(Layer7_Attention_Transpose, 0, Layer7_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer7_Attention_Z_MatMul");
  auto Layer7_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer7_Attention_Z_Mask_Reshape");
  auto Layer7_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer7_Attention_Z_Mask_Reshape,
                            Layer7_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer7_Attention_Z_Mask_AttentionMask0"}});
  auto Layer7_Attention_Z_Mask_AttentionMask0 =
      Layer7_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer7_Attention_Z_ApplyMask = odla_Add(
      Layer7_Attention_Z_MatMul, Layer7_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer7_Attention_Z_ApplyMask");
  auto Layer7_Attention_Z_Softmax =
      odla_Softmax(Layer7_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer7_Attention_Z_Softmax");
  auto Layer7_Attention_Z_MatMul_1 =
      odla_Gemm(Layer7_Attention_Z_Softmax, 0, Layer7_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer7_Attention_Z_MatMul_1");
  auto Layer7_Attention_Z_Transpose = odla_Transpose(
      Layer7_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer7_Attention_Z_Transpose");
  auto Layer7_Attention_Z_Reshape = odla_Reshape(
      Layer7_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer7_Attention_Z_Reshape");
  auto Layer7_Attention_MatMul_3 =
      odla_Gemm(Layer7_Attention_Z_Reshape, 0, Layer7_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer7_Attention_MatMul_3");
  auto Layer7_Attention_Add =
      odla_Add(Layer7_Attention_MatMul_3, Layer7_Attention_Out_Bias_,
               (const odla_value_id) "Layer7_Attention_Add");
  auto Layer7_Attention_Add_1 =
      odla_Add(Layer6_FF_GroupNormalization, Layer7_Attention_Add,
               (const odla_value_id) "Layer7_Attention_Add_1");
  auto Layer7_Attention_GroupNormalization = odla_GroupNormalization(
      Layer7_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer7_Attention_Gamma_, Layer7_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer7_Attention_GroupNormalization");
  auto Layer7_FF_1_MatMul =
      odla_Gemm(Layer7_Attention_GroupNormalization, 0, Layer7_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer7_FF_1_MatMul");
  auto Layer7_FF_1_Add = odla_Add(Layer7_FF_1_MatMul, Layer7_FF_1_B_,
                                  (const odla_value_id) "Layer7_FF_1_Add");
  auto Layer7_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer7_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer7_FF_Gelu0"}});
  auto Layer7_FF_Gelu0 = Layer7_FF_Gelu0_array.values[0];
  auto Layer7_FF_2_MatMul =
      odla_Gemm(Layer7_FF_Gelu0, 0, Layer7_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer7_FF_2_MatMul");
  auto Layer7_FF_2_Add = odla_Add(Layer7_FF_2_MatMul, Layer7_FF_2_B_,
                                  (const odla_value_id) "Layer7_FF_2_Add");
  auto Layer7_FF_Add =
      odla_Add(Layer7_Attention_GroupNormalization, Layer7_FF_2_Add,
               (const odla_value_id) "Layer7_FF_Add");
  auto Layer7_FF_GroupNormalization = odla_GroupNormalization(
      Layer7_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer7_FF_Gamma_, Layer7_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer7_FF_GroupNormalization");
  auto Layer8_Attention_MatMul =
      odla_Gemm(Layer7_FF_GroupNormalization, 0, Layer8_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer8_Attention_MatMul");
  auto Layer8_Attention_MatMul_1 =
      odla_Gemm(Layer7_FF_GroupNormalization, 0, Layer8_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer8_Attention_MatMul_1");
  auto Layer8_Attention_MatMul_2 =
      odla_Gemm(Layer7_FF_GroupNormalization, 0, Layer8_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer8_Attention_MatMul_2");
  auto Layer8_Attention_Reshape = odla_Reshape(
      Layer8_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer8_Attention_Reshape");
  auto Layer8_Attention_Transpose = odla_Transpose(
      Layer8_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer8_Attention_Transpose");
  auto Layer8_Attention_Reshape_1 = odla_Reshape(
      Layer8_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer8_Attention_Reshape_1");
  auto Layer8_Attention_Transpose_1 = odla_Transpose(
      Layer8_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer8_Attention_Transpose_1");
  auto Layer8_Attention_Reshape_2 = odla_Reshape(
      Layer8_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer8_Attention_Reshape_2");
  auto Layer8_Attention_Transpose_2 = odla_Transpose(
      Layer8_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer8_Attention_Transpose_2");
  auto Layer8_Attention_Z_MatMul =
      odla_Gemm(Layer8_Attention_Transpose, 0, Layer8_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer8_Attention_Z_MatMul");
  auto Layer8_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer8_Attention_Z_Mask_Reshape");
  auto Layer8_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer8_Attention_Z_Mask_Reshape,
                            Layer8_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer8_Attention_Z_Mask_AttentionMask0"}});
  auto Layer8_Attention_Z_Mask_AttentionMask0 =
      Layer8_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer8_Attention_Z_ApplyMask = odla_Add(
      Layer8_Attention_Z_MatMul, Layer8_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer8_Attention_Z_ApplyMask");
  auto Layer8_Attention_Z_Softmax =
      odla_Softmax(Layer8_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer8_Attention_Z_Softmax");
  auto Layer8_Attention_Z_MatMul_1 =
      odla_Gemm(Layer8_Attention_Z_Softmax, 0, Layer8_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer8_Attention_Z_MatMul_1");
  auto Layer8_Attention_Z_Transpose = odla_Transpose(
      Layer8_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer8_Attention_Z_Transpose");
  auto Layer8_Attention_Z_Reshape = odla_Reshape(
      Layer8_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer8_Attention_Z_Reshape");
  auto Layer8_Attention_MatMul_3 =
      odla_Gemm(Layer8_Attention_Z_Reshape, 0, Layer8_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer8_Attention_MatMul_3");
  auto Layer8_Attention_Add =
      odla_Add(Layer8_Attention_MatMul_3, Layer8_Attention_Out_Bias_,
               (const odla_value_id) "Layer8_Attention_Add");
  auto Layer8_Attention_Add_1 =
      odla_Add(Layer7_FF_GroupNormalization, Layer8_Attention_Add,
               (const odla_value_id) "Layer8_Attention_Add_1");
  auto Layer8_Attention_GroupNormalization = odla_GroupNormalization(
      Layer8_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer8_Attention_Gamma_, Layer8_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer8_Attention_GroupNormalization");
  auto Layer8_FF_1_MatMul =
      odla_Gemm(Layer8_Attention_GroupNormalization, 0, Layer8_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer8_FF_1_MatMul");
  auto Layer8_FF_1_Add = odla_Add(Layer8_FF_1_MatMul, Layer8_FF_1_B_,
                                  (const odla_value_id) "Layer8_FF_1_Add");
  auto Layer8_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer8_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer8_FF_Gelu0"}});
  auto Layer8_FF_Gelu0 = Layer8_FF_Gelu0_array.values[0];
  auto Layer8_FF_2_MatMul =
      odla_Gemm(Layer8_FF_Gelu0, 0, Layer8_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer8_FF_2_MatMul");
  auto Layer8_FF_2_Add = odla_Add(Layer8_FF_2_MatMul, Layer8_FF_2_B_,
                                  (const odla_value_id) "Layer8_FF_2_Add");
  auto Layer8_FF_Add =
      odla_Add(Layer8_Attention_GroupNormalization, Layer8_FF_2_Add,
               (const odla_value_id) "Layer8_FF_Add");
  auto Layer8_FF_GroupNormalization = odla_GroupNormalization(
      Layer8_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer8_FF_Gamma_, Layer8_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer8_FF_GroupNormalization");
  auto Layer9_Attention_MatMul =
      odla_Gemm(Layer8_FF_GroupNormalization, 0, Layer9_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer9_Attention_MatMul");
  auto Layer9_Attention_MatMul_1 =
      odla_Gemm(Layer8_FF_GroupNormalization, 0, Layer9_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer9_Attention_MatMul_1");
  auto Layer9_Attention_MatMul_2 =
      odla_Gemm(Layer8_FF_GroupNormalization, 0, Layer9_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer9_Attention_MatMul_2");
  auto Layer9_Attention_Reshape = odla_Reshape(
      Layer9_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer9_Attention_Reshape");
  auto Layer9_Attention_Transpose = odla_Transpose(
      Layer9_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer9_Attention_Transpose");
  auto Layer9_Attention_Reshape_1 = odla_Reshape(
      Layer9_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer9_Attention_Reshape_1");
  auto Layer9_Attention_Transpose_1 = odla_Transpose(
      Layer9_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer9_Attention_Transpose_1");
  auto Layer9_Attention_Reshape_2 = odla_Reshape(
      Layer9_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer9_Attention_Reshape_2");
  auto Layer9_Attention_Transpose_2 = odla_Transpose(
      Layer9_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer9_Attention_Transpose_2");
  auto Layer9_Attention_Z_MatMul =
      odla_Gemm(Layer9_Attention_Transpose, 0, Layer9_Attention_Transpose_1, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer9_Attention_Z_MatMul");
  auto Layer9_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer9_Attention_Z_Mask_Reshape");
  auto Layer9_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer9_Attention_Z_Mask_Reshape,
                            Layer9_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer9_Attention_Z_Mask_AttentionMask0"}});
  auto Layer9_Attention_Z_Mask_AttentionMask0 =
      Layer9_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer9_Attention_Z_ApplyMask = odla_Add(
      Layer9_Attention_Z_MatMul, Layer9_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer9_Attention_Z_ApplyMask");
  auto Layer9_Attention_Z_Softmax =
      odla_Softmax(Layer9_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer9_Attention_Z_Softmax");
  auto Layer9_Attention_Z_MatMul_1 =
      odla_Gemm(Layer9_Attention_Z_Softmax, 0, Layer9_Attention_Transpose_2, 0,
                1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer9_Attention_Z_MatMul_1");
  auto Layer9_Attention_Z_Transpose = odla_Transpose(
      Layer9_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer9_Attention_Z_Transpose");
  auto Layer9_Attention_Z_Reshape = odla_Reshape(
      Layer9_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer9_Attention_Z_Reshape");
  auto Layer9_Attention_MatMul_3 =
      odla_Gemm(Layer9_Attention_Z_Reshape, 0, Layer9_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer9_Attention_MatMul_3");
  auto Layer9_Attention_Add =
      odla_Add(Layer9_Attention_MatMul_3, Layer9_Attention_Out_Bias_,
               (const odla_value_id) "Layer9_Attention_Add");
  auto Layer9_Attention_Add_1 =
      odla_Add(Layer8_FF_GroupNormalization, Layer9_Attention_Add,
               (const odla_value_id) "Layer9_Attention_Add_1");
  auto Layer9_Attention_GroupNormalization = odla_GroupNormalization(
      Layer9_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer9_Attention_Gamma_, Layer9_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer9_Attention_GroupNormalization");
  auto Layer9_FF_1_MatMul =
      odla_Gemm(Layer9_Attention_GroupNormalization, 0, Layer9_FF_1_W_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer9_FF_1_MatMul");
  auto Layer9_FF_1_Add = odla_Add(Layer9_FF_1_MatMul, Layer9_FF_1_B_,
                                  (const odla_value_id) "Layer9_FF_1_Add");
  auto Layer9_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer9_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer9_FF_Gelu0"}});
  auto Layer9_FF_Gelu0 = Layer9_FF_Gelu0_array.values[0];
  auto Layer9_FF_2_MatMul =
      odla_Gemm(Layer9_FF_Gelu0, 0, Layer9_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer9_FF_2_MatMul");
  auto Layer9_FF_2_Add = odla_Add(Layer9_FF_2_MatMul, Layer9_FF_2_B_,
                                  (const odla_value_id) "Layer9_FF_2_Add");
  auto Layer9_FF_Add =
      odla_Add(Layer9_Attention_GroupNormalization, Layer9_FF_2_Add,
               (const odla_value_id) "Layer9_FF_Add");
  auto Layer9_FF_GroupNormalization = odla_GroupNormalization(
      Layer9_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer9_FF_Gamma_, Layer9_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer9_FF_GroupNormalization");
  auto Layer10_Attention_MatMul =
      odla_Gemm(Layer9_FF_GroupNormalization, 0, Layer10_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer10_Attention_MatMul");
  auto Layer10_Attention_MatMul_1 =
      odla_Gemm(Layer9_FF_GroupNormalization, 0, Layer10_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer10_Attention_MatMul_1");
  auto Layer10_Attention_MatMul_2 =
      odla_Gemm(Layer9_FF_GroupNormalization, 0, Layer10_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer10_Attention_MatMul_2");
  auto Layer10_Attention_Reshape = odla_Reshape(
      Layer10_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer10_Attention_Reshape");
  auto Layer10_Attention_Transpose = odla_Transpose(
      Layer10_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer10_Attention_Transpose");
  auto Layer10_Attention_Reshape_1 = odla_Reshape(
      Layer10_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer10_Attention_Reshape_1");
  auto Layer10_Attention_Transpose_1 = odla_Transpose(
      Layer10_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer10_Attention_Transpose_1");
  auto Layer10_Attention_Reshape_2 = odla_Reshape(
      Layer10_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer10_Attention_Reshape_2");
  auto Layer10_Attention_Transpose_2 = odla_Transpose(
      Layer10_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer10_Attention_Transpose_2");
  auto Layer10_Attention_Z_MatMul =
      odla_Gemm(Layer10_Attention_Transpose, 0, Layer10_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer10_Attention_Z_MatMul");
  auto Layer10_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer10_Attention_Z_Mask_Reshape");
  auto Layer10_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer10_Attention_Z_Mask_Reshape,
                            Layer10_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer10_Attention_Z_Mask_AttentionMask0"}});
  auto Layer10_Attention_Z_Mask_AttentionMask0 =
      Layer10_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer10_Attention_Z_ApplyMask = odla_Add(
      Layer10_Attention_Z_MatMul, Layer10_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer10_Attention_Z_ApplyMask");
  auto Layer10_Attention_Z_Softmax =
      odla_Softmax(Layer10_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer10_Attention_Z_Softmax");
  auto Layer10_Attention_Z_MatMul_1 =
      odla_Gemm(Layer10_Attention_Z_Softmax, 0, Layer10_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer10_Attention_Z_MatMul_1");
  auto Layer10_Attention_Z_Transpose = odla_Transpose(
      Layer10_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer10_Attention_Z_Transpose");
  auto Layer10_Attention_Z_Reshape = odla_Reshape(
      Layer10_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer10_Attention_Z_Reshape");
  auto Layer10_Attention_MatMul_3 =
      odla_Gemm(Layer10_Attention_Z_Reshape, 0, Layer10_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer10_Attention_MatMul_3");
  auto Layer10_Attention_Add =
      odla_Add(Layer10_Attention_MatMul_3, Layer10_Attention_Out_Bias_,
               (const odla_value_id) "Layer10_Attention_Add");
  auto Layer10_Attention_Add_1 =
      odla_Add(Layer9_FF_GroupNormalization, Layer10_Attention_Add,
               (const odla_value_id) "Layer10_Attention_Add_1");
  auto Layer10_Attention_GroupNormalization = odla_GroupNormalization(
      Layer10_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer10_Attention_Gamma_, Layer10_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer10_Attention_GroupNormalization");
  auto Layer10_FF_1_MatMul =
      odla_Gemm(Layer10_Attention_GroupNormalization, 0, Layer10_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer10_FF_1_MatMul");
  auto Layer10_FF_1_Add = odla_Add(Layer10_FF_1_MatMul, Layer10_FF_1_B_,
                                   (const odla_value_id) "Layer10_FF_1_Add");
  auto Layer10_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer10_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer10_FF_Gelu0"}});
  auto Layer10_FF_Gelu0 = Layer10_FF_Gelu0_array.values[0];
  auto Layer10_FF_2_MatMul =
      odla_Gemm(Layer10_FF_Gelu0, 0, Layer10_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer10_FF_2_MatMul");
  auto Layer10_FF_2_Add = odla_Add(Layer10_FF_2_MatMul, Layer10_FF_2_B_,
                                   (const odla_value_id) "Layer10_FF_2_Add");
  auto Layer10_FF_Add =
      odla_Add(Layer10_Attention_GroupNormalization, Layer10_FF_2_Add,
               (const odla_value_id) "Layer10_FF_Add");
  auto Layer10_FF_GroupNormalization = odla_GroupNormalization(
      Layer10_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer10_FF_Gamma_, Layer10_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer10_FF_GroupNormalization");
  auto Layer11_Attention_MatMul =
      odla_Gemm(Layer10_FF_GroupNormalization, 0, Layer11_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer11_Attention_MatMul");
  auto Layer11_Attention_MatMul_1 =
      odla_Gemm(Layer10_FF_GroupNormalization, 0, Layer11_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer11_Attention_MatMul_1");
  auto Layer11_Attention_MatMul_2 =
      odla_Gemm(Layer10_FF_GroupNormalization, 0, Layer11_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer11_Attention_MatMul_2");
  auto Layer11_Attention_Reshape = odla_Reshape(
      Layer11_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer11_Attention_Reshape");
  auto Layer11_Attention_Transpose = odla_Transpose(
      Layer11_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer11_Attention_Transpose");
  auto Layer11_Attention_Reshape_1 = odla_Reshape(
      Layer11_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer11_Attention_Reshape_1");
  auto Layer11_Attention_Transpose_1 = odla_Transpose(
      Layer11_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer11_Attention_Transpose_1");
  auto Layer11_Attention_Reshape_2 = odla_Reshape(
      Layer11_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer11_Attention_Reshape_2");
  auto Layer11_Attention_Transpose_2 = odla_Transpose(
      Layer11_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer11_Attention_Transpose_2");
  auto Layer11_Attention_Z_MatMul =
      odla_Gemm(Layer11_Attention_Transpose, 0, Layer11_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer11_Attention_Z_MatMul");
  auto Layer11_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer11_Attention_Z_Mask_Reshape");
  auto Layer11_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer11_Attention_Z_Mask_Reshape,
                            Layer11_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer11_Attention_Z_Mask_AttentionMask0"}});
  auto Layer11_Attention_Z_Mask_AttentionMask0 =
      Layer11_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer11_Attention_Z_ApplyMask = odla_Add(
      Layer11_Attention_Z_MatMul, Layer11_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer11_Attention_Z_ApplyMask");
  auto Layer11_Attention_Z_Softmax =
      odla_Softmax(Layer11_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer11_Attention_Z_Softmax");
  auto Layer11_Attention_Z_MatMul_1 =
      odla_Gemm(Layer11_Attention_Z_Softmax, 0, Layer11_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer11_Attention_Z_MatMul_1");
  auto Layer11_Attention_Z_Transpose = odla_Transpose(
      Layer11_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer11_Attention_Z_Transpose");
  auto Layer11_Attention_Z_Reshape = odla_Reshape(
      Layer11_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer11_Attention_Z_Reshape");
  auto Layer11_Attention_MatMul_3 =
      odla_Gemm(Layer11_Attention_Z_Reshape, 0, Layer11_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer11_Attention_MatMul_3");
  auto Layer11_Attention_Add =
      odla_Add(Layer11_Attention_MatMul_3, Layer11_Attention_Out_Bias_,
               (const odla_value_id) "Layer11_Attention_Add");
  auto Layer11_Attention_Add_1 =
      odla_Add(Layer10_FF_GroupNormalization, Layer11_Attention_Add,
               (const odla_value_id) "Layer11_Attention_Add_1");
  auto Layer11_Attention_GroupNormalization = odla_GroupNormalization(
      Layer11_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer11_Attention_Gamma_, Layer11_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer11_Attention_GroupNormalization");
  auto Layer11_FF_1_MatMul =
      odla_Gemm(Layer11_Attention_GroupNormalization, 0, Layer11_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer11_FF_1_MatMul");
  auto Layer11_FF_1_Add = odla_Add(Layer11_FF_1_MatMul, Layer11_FF_1_B_,
                                   (const odla_value_id) "Layer11_FF_1_Add");
  auto Layer11_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer11_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer11_FF_Gelu0"}});
  auto Layer11_FF_Gelu0 = Layer11_FF_Gelu0_array.values[0];
  auto Layer11_FF_2_MatMul =
      odla_Gemm(Layer11_FF_Gelu0, 0, Layer11_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer11_FF_2_MatMul");
  auto Layer11_FF_2_Add = odla_Add(Layer11_FF_2_MatMul, Layer11_FF_2_B_,
                                   (const odla_value_id) "Layer11_FF_2_Add");
  auto Layer11_FF_Add =
      odla_Add(Layer11_Attention_GroupNormalization, Layer11_FF_2_Add,
               (const odla_value_id) "Layer11_FF_Add");
  auto Layer11_FF_GroupNormalization = odla_GroupNormalization(
      Layer11_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer11_FF_Gamma_, Layer11_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer11_FF_GroupNormalization");
  auto Layer12_Attention_MatMul =
      odla_Gemm(Layer11_FF_GroupNormalization, 0, Layer12_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer12_Attention_MatMul");
  auto Layer12_Attention_MatMul_1 =
      odla_Gemm(Layer11_FF_GroupNormalization, 0, Layer12_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer12_Attention_MatMul_1");
  auto Layer12_Attention_MatMul_2 =
      odla_Gemm(Layer11_FF_GroupNormalization, 0, Layer12_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer12_Attention_MatMul_2");
  auto Layer12_Attention_Reshape = odla_Reshape(
      Layer12_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer12_Attention_Reshape");
  auto Layer12_Attention_Transpose = odla_Transpose(
      Layer12_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer12_Attention_Transpose");
  auto Layer12_Attention_Reshape_1 = odla_Reshape(
      Layer12_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer12_Attention_Reshape_1");
  auto Layer12_Attention_Transpose_1 = odla_Transpose(
      Layer12_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer12_Attention_Transpose_1");
  auto Layer12_Attention_Reshape_2 = odla_Reshape(
      Layer12_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer12_Attention_Reshape_2");
  auto Layer12_Attention_Transpose_2 = odla_Transpose(
      Layer12_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer12_Attention_Transpose_2");
  auto Layer12_Attention_Z_MatMul =
      odla_Gemm(Layer12_Attention_Transpose, 0, Layer12_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer12_Attention_Z_MatMul");
  auto Layer12_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer12_Attention_Z_Mask_Reshape");
  auto Layer12_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer12_Attention_Z_Mask_Reshape,
                            Layer12_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer12_Attention_Z_Mask_AttentionMask0"}});
  auto Layer12_Attention_Z_Mask_AttentionMask0 =
      Layer12_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer12_Attention_Z_ApplyMask = odla_Add(
      Layer12_Attention_Z_MatMul, Layer12_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer12_Attention_Z_ApplyMask");
  auto Layer12_Attention_Z_Softmax =
      odla_Softmax(Layer12_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer12_Attention_Z_Softmax");
  auto Layer12_Attention_Z_MatMul_1 =
      odla_Gemm(Layer12_Attention_Z_Softmax, 0, Layer12_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer12_Attention_Z_MatMul_1");
  auto Layer12_Attention_Z_Transpose = odla_Transpose(
      Layer12_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer12_Attention_Z_Transpose");
  auto Layer12_Attention_Z_Reshape = odla_Reshape(
      Layer12_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer12_Attention_Z_Reshape");
  auto Layer12_Attention_MatMul_3 =
      odla_Gemm(Layer12_Attention_Z_Reshape, 0, Layer12_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer12_Attention_MatMul_3");
  auto Layer12_Attention_Add =
      odla_Add(Layer12_Attention_MatMul_3, Layer12_Attention_Out_Bias_,
               (const odla_value_id) "Layer12_Attention_Add");
  auto Layer12_Attention_Add_1 =
      odla_Add(Layer11_FF_GroupNormalization, Layer12_Attention_Add,
               (const odla_value_id) "Layer12_Attention_Add_1");
  auto Layer12_Attention_GroupNormalization = odla_GroupNormalization(
      Layer12_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer12_Attention_Gamma_, Layer12_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer12_Attention_GroupNormalization");
  auto Layer12_FF_1_MatMul =
      odla_Gemm(Layer12_Attention_GroupNormalization, 0, Layer12_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer12_FF_1_MatMul");
  auto Layer12_FF_1_Add = odla_Add(Layer12_FF_1_MatMul, Layer12_FF_1_B_,
                                   (const odla_value_id) "Layer12_FF_1_Add");
  auto Layer12_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer12_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer12_FF_Gelu0"}});
  auto Layer12_FF_Gelu0 = Layer12_FF_Gelu0_array.values[0];
  auto Layer12_FF_2_MatMul =
      odla_Gemm(Layer12_FF_Gelu0, 0, Layer12_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer12_FF_2_MatMul");
  auto Layer12_FF_2_Add = odla_Add(Layer12_FF_2_MatMul, Layer12_FF_2_B_,
                                   (const odla_value_id) "Layer12_FF_2_Add");
  auto Layer12_FF_Add =
      odla_Add(Layer12_Attention_GroupNormalization, Layer12_FF_2_Add,
               (const odla_value_id) "Layer12_FF_Add");
  auto Layer12_FF_GroupNormalization = odla_GroupNormalization(
      Layer12_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer12_FF_Gamma_, Layer12_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer12_FF_GroupNormalization");
  auto Layer13_Attention_MatMul =
      odla_Gemm(Layer12_FF_GroupNormalization, 0, Layer13_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer13_Attention_MatMul");
  auto Layer13_Attention_MatMul_1 =
      odla_Gemm(Layer12_FF_GroupNormalization, 0, Layer13_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer13_Attention_MatMul_1");
  auto Layer13_Attention_MatMul_2 =
      odla_Gemm(Layer12_FF_GroupNormalization, 0, Layer13_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer13_Attention_MatMul_2");
  auto Layer13_Attention_Reshape = odla_Reshape(
      Layer13_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer13_Attention_Reshape");
  auto Layer13_Attention_Transpose = odla_Transpose(
      Layer13_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer13_Attention_Transpose");
  auto Layer13_Attention_Reshape_1 = odla_Reshape(
      Layer13_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer13_Attention_Reshape_1");
  auto Layer13_Attention_Transpose_1 = odla_Transpose(
      Layer13_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer13_Attention_Transpose_1");
  auto Layer13_Attention_Reshape_2 = odla_Reshape(
      Layer13_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer13_Attention_Reshape_2");
  auto Layer13_Attention_Transpose_2 = odla_Transpose(
      Layer13_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer13_Attention_Transpose_2");
  auto Layer13_Attention_Z_MatMul =
      odla_Gemm(Layer13_Attention_Transpose, 0, Layer13_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer13_Attention_Z_MatMul");
  auto Layer13_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer13_Attention_Z_Mask_Reshape");
  auto Layer13_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer13_Attention_Z_Mask_Reshape,
                            Layer13_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer13_Attention_Z_Mask_AttentionMask0"}});
  auto Layer13_Attention_Z_Mask_AttentionMask0 =
      Layer13_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer13_Attention_Z_ApplyMask = odla_Add(
      Layer13_Attention_Z_MatMul, Layer13_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer13_Attention_Z_ApplyMask");
  auto Layer13_Attention_Z_Softmax =
      odla_Softmax(Layer13_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer13_Attention_Z_Softmax");
  auto Layer13_Attention_Z_MatMul_1 =
      odla_Gemm(Layer13_Attention_Z_Softmax, 0, Layer13_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer13_Attention_Z_MatMul_1");
  auto Layer13_Attention_Z_Transpose = odla_Transpose(
      Layer13_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer13_Attention_Z_Transpose");
  auto Layer13_Attention_Z_Reshape = odla_Reshape(
      Layer13_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer13_Attention_Z_Reshape");
  auto Layer13_Attention_MatMul_3 =
      odla_Gemm(Layer13_Attention_Z_Reshape, 0, Layer13_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer13_Attention_MatMul_3");
  auto Layer13_Attention_Add =
      odla_Add(Layer13_Attention_MatMul_3, Layer13_Attention_Out_Bias_,
               (const odla_value_id) "Layer13_Attention_Add");
  auto Layer13_Attention_Add_1 =
      odla_Add(Layer12_FF_GroupNormalization, Layer13_Attention_Add,
               (const odla_value_id) "Layer13_Attention_Add_1");
  auto Layer13_Attention_GroupNormalization = odla_GroupNormalization(
      Layer13_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer13_Attention_Gamma_, Layer13_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer13_Attention_GroupNormalization");
  auto Layer13_FF_1_MatMul =
      odla_Gemm(Layer13_Attention_GroupNormalization, 0, Layer13_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer13_FF_1_MatMul");
  auto Layer13_FF_1_Add = odla_Add(Layer13_FF_1_MatMul, Layer13_FF_1_B_,
                                   (const odla_value_id) "Layer13_FF_1_Add");
  auto Layer13_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer13_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer13_FF_Gelu0"}});
  auto Layer13_FF_Gelu0 = Layer13_FF_Gelu0_array.values[0];
  auto Layer13_FF_2_MatMul =
      odla_Gemm(Layer13_FF_Gelu0, 0, Layer13_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer13_FF_2_MatMul");
  auto Layer13_FF_2_Add = odla_Add(Layer13_FF_2_MatMul, Layer13_FF_2_B_,
                                   (const odla_value_id) "Layer13_FF_2_Add");
  auto Layer13_FF_Add =
      odla_Add(Layer13_Attention_GroupNormalization, Layer13_FF_2_Add,
               (const odla_value_id) "Layer13_FF_Add");
  auto Layer13_FF_GroupNormalization = odla_GroupNormalization(
      Layer13_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer13_FF_Gamma_, Layer13_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer13_FF_GroupNormalization");
  auto Layer14_Attention_MatMul =
      odla_Gemm(Layer13_FF_GroupNormalization, 0, Layer14_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer14_Attention_MatMul");
  auto Layer14_Attention_MatMul_1 =
      odla_Gemm(Layer13_FF_GroupNormalization, 0, Layer14_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer14_Attention_MatMul_1");
  auto Layer14_Attention_MatMul_2 =
      odla_Gemm(Layer13_FF_GroupNormalization, 0, Layer14_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer14_Attention_MatMul_2");
  auto Layer14_Attention_Reshape = odla_Reshape(
      Layer14_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer14_Attention_Reshape");
  auto Layer14_Attention_Transpose = odla_Transpose(
      Layer14_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer14_Attention_Transpose");
  auto Layer14_Attention_Reshape_1 = odla_Reshape(
      Layer14_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer14_Attention_Reshape_1");
  auto Layer14_Attention_Transpose_1 = odla_Transpose(
      Layer14_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer14_Attention_Transpose_1");
  auto Layer14_Attention_Reshape_2 = odla_Reshape(
      Layer14_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer14_Attention_Reshape_2");
  auto Layer14_Attention_Transpose_2 = odla_Transpose(
      Layer14_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer14_Attention_Transpose_2");
  auto Layer14_Attention_Z_MatMul =
      odla_Gemm(Layer14_Attention_Transpose, 0, Layer14_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer14_Attention_Z_MatMul");
  auto Layer14_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer14_Attention_Z_Mask_Reshape");
  auto Layer14_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer14_Attention_Z_Mask_Reshape,
                            Layer14_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer14_Attention_Z_Mask_AttentionMask0"}});
  auto Layer14_Attention_Z_Mask_AttentionMask0 =
      Layer14_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer14_Attention_Z_ApplyMask = odla_Add(
      Layer14_Attention_Z_MatMul, Layer14_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer14_Attention_Z_ApplyMask");
  auto Layer14_Attention_Z_Softmax =
      odla_Softmax(Layer14_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer14_Attention_Z_Softmax");
  auto Layer14_Attention_Z_MatMul_1 =
      odla_Gemm(Layer14_Attention_Z_Softmax, 0, Layer14_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer14_Attention_Z_MatMul_1");
  auto Layer14_Attention_Z_Transpose = odla_Transpose(
      Layer14_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer14_Attention_Z_Transpose");
  auto Layer14_Attention_Z_Reshape = odla_Reshape(
      Layer14_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer14_Attention_Z_Reshape");
  auto Layer14_Attention_MatMul_3 =
      odla_Gemm(Layer14_Attention_Z_Reshape, 0, Layer14_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer14_Attention_MatMul_3");
  auto Layer14_Attention_Add =
      odla_Add(Layer14_Attention_MatMul_3, Layer14_Attention_Out_Bias_,
               (const odla_value_id) "Layer14_Attention_Add");
  auto Layer14_Attention_Add_1 =
      odla_Add(Layer13_FF_GroupNormalization, Layer14_Attention_Add,
               (const odla_value_id) "Layer14_Attention_Add_1");
  auto Layer14_Attention_GroupNormalization = odla_GroupNormalization(
      Layer14_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer14_Attention_Gamma_, Layer14_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer14_Attention_GroupNormalization");
  auto Layer14_FF_1_MatMul =
      odla_Gemm(Layer14_Attention_GroupNormalization, 0, Layer14_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer14_FF_1_MatMul");
  auto Layer14_FF_1_Add = odla_Add(Layer14_FF_1_MatMul, Layer14_FF_1_B_,
                                   (const odla_value_id) "Layer14_FF_1_Add");
  auto Layer14_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer14_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer14_FF_Gelu0"}});
  auto Layer14_FF_Gelu0 = Layer14_FF_Gelu0_array.values[0];
  auto Layer14_FF_2_MatMul =
      odla_Gemm(Layer14_FF_Gelu0, 0, Layer14_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer14_FF_2_MatMul");
  auto Layer14_FF_2_Add = odla_Add(Layer14_FF_2_MatMul, Layer14_FF_2_B_,
                                   (const odla_value_id) "Layer14_FF_2_Add");
  auto Layer14_FF_Add =
      odla_Add(Layer14_Attention_GroupNormalization, Layer14_FF_2_Add,
               (const odla_value_id) "Layer14_FF_Add");
  auto Layer14_FF_GroupNormalization = odla_GroupNormalization(
      Layer14_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer14_FF_Gamma_, Layer14_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer14_FF_GroupNormalization");
  auto Layer15_Attention_MatMul =
      odla_Gemm(Layer14_FF_GroupNormalization, 0, Layer15_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer15_Attention_MatMul");
  auto Layer15_Attention_MatMul_1 =
      odla_Gemm(Layer14_FF_GroupNormalization, 0, Layer15_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer15_Attention_MatMul_1");
  auto Layer15_Attention_MatMul_2 =
      odla_Gemm(Layer14_FF_GroupNormalization, 0, Layer15_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer15_Attention_MatMul_2");
  auto Layer15_Attention_Reshape = odla_Reshape(
      Layer15_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer15_Attention_Reshape");
  auto Layer15_Attention_Transpose = odla_Transpose(
      Layer15_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer15_Attention_Transpose");
  auto Layer15_Attention_Reshape_1 = odla_Reshape(
      Layer15_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer15_Attention_Reshape_1");
  auto Layer15_Attention_Transpose_1 = odla_Transpose(
      Layer15_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer15_Attention_Transpose_1");
  auto Layer15_Attention_Reshape_2 = odla_Reshape(
      Layer15_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer15_Attention_Reshape_2");
  auto Layer15_Attention_Transpose_2 = odla_Transpose(
      Layer15_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer15_Attention_Transpose_2");
  auto Layer15_Attention_Z_MatMul =
      odla_Gemm(Layer15_Attention_Transpose, 0, Layer15_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer15_Attention_Z_MatMul");
  auto Layer15_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer15_Attention_Z_Mask_Reshape");
  auto Layer15_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer15_Attention_Z_Mask_Reshape,
                            Layer15_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer15_Attention_Z_Mask_AttentionMask0"}});
  auto Layer15_Attention_Z_Mask_AttentionMask0 =
      Layer15_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer15_Attention_Z_ApplyMask = odla_Add(
      Layer15_Attention_Z_MatMul, Layer15_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer15_Attention_Z_ApplyMask");
  auto Layer15_Attention_Z_Softmax =
      odla_Softmax(Layer15_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer15_Attention_Z_Softmax");
  auto Layer15_Attention_Z_MatMul_1 =
      odla_Gemm(Layer15_Attention_Z_Softmax, 0, Layer15_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer15_Attention_Z_MatMul_1");
  auto Layer15_Attention_Z_Transpose = odla_Transpose(
      Layer15_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer15_Attention_Z_Transpose");
  auto Layer15_Attention_Z_Reshape = odla_Reshape(
      Layer15_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer15_Attention_Z_Reshape");
  auto Layer15_Attention_MatMul_3 =
      odla_Gemm(Layer15_Attention_Z_Reshape, 0, Layer15_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer15_Attention_MatMul_3");
  auto Layer15_Attention_Add =
      odla_Add(Layer15_Attention_MatMul_3, Layer15_Attention_Out_Bias_,
               (const odla_value_id) "Layer15_Attention_Add");
  auto Layer15_Attention_Add_1 =
      odla_Add(Layer14_FF_GroupNormalization, Layer15_Attention_Add,
               (const odla_value_id) "Layer15_Attention_Add_1");
  auto Layer15_Attention_GroupNormalization = odla_GroupNormalization(
      Layer15_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer15_Attention_Gamma_, Layer15_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer15_Attention_GroupNormalization");
  auto Layer15_FF_1_MatMul =
      odla_Gemm(Layer15_Attention_GroupNormalization, 0, Layer15_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer15_FF_1_MatMul");
  auto Layer15_FF_1_Add = odla_Add(Layer15_FF_1_MatMul, Layer15_FF_1_B_,
                                   (const odla_value_id) "Layer15_FF_1_Add");
  auto Layer15_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer15_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer15_FF_Gelu0"}});
  auto Layer15_FF_Gelu0 = Layer15_FF_Gelu0_array.values[0];
  auto Layer15_FF_2_MatMul =
      odla_Gemm(Layer15_FF_Gelu0, 0, Layer15_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer15_FF_2_MatMul");
  auto Layer15_FF_2_Add = odla_Add(Layer15_FF_2_MatMul, Layer15_FF_2_B_,
                                   (const odla_value_id) "Layer15_FF_2_Add");
  auto Layer15_FF_Add =
      odla_Add(Layer15_Attention_GroupNormalization, Layer15_FF_2_Add,
               (const odla_value_id) "Layer15_FF_Add");
  auto Layer15_FF_GroupNormalization = odla_GroupNormalization(
      Layer15_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer15_FF_Gamma_, Layer15_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer15_FF_GroupNormalization");
  auto Layer16_Attention_MatMul =
      odla_Gemm(Layer15_FF_GroupNormalization, 0, Layer16_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer16_Attention_MatMul");
  auto Layer16_Attention_MatMul_1 =
      odla_Gemm(Layer15_FF_GroupNormalization, 0, Layer16_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer16_Attention_MatMul_1");
  auto Layer16_Attention_MatMul_2 =
      odla_Gemm(Layer15_FF_GroupNormalization, 0, Layer16_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer16_Attention_MatMul_2");
  auto Layer16_Attention_Reshape = odla_Reshape(
      Layer16_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer16_Attention_Reshape");
  auto Layer16_Attention_Transpose = odla_Transpose(
      Layer16_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer16_Attention_Transpose");
  auto Layer16_Attention_Reshape_1 = odla_Reshape(
      Layer16_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer16_Attention_Reshape_1");
  auto Layer16_Attention_Transpose_1 = odla_Transpose(
      Layer16_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer16_Attention_Transpose_1");
  auto Layer16_Attention_Reshape_2 = odla_Reshape(
      Layer16_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer16_Attention_Reshape_2");
  auto Layer16_Attention_Transpose_2 = odla_Transpose(
      Layer16_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer16_Attention_Transpose_2");
  auto Layer16_Attention_Z_MatMul =
      odla_Gemm(Layer16_Attention_Transpose, 0, Layer16_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer16_Attention_Z_MatMul");
  auto Layer16_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer16_Attention_Z_Mask_Reshape");
  auto Layer16_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer16_Attention_Z_Mask_Reshape,
                            Layer16_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer16_Attention_Z_Mask_AttentionMask0"}});
  auto Layer16_Attention_Z_Mask_AttentionMask0 =
      Layer16_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer16_Attention_Z_ApplyMask = odla_Add(
      Layer16_Attention_Z_MatMul, Layer16_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer16_Attention_Z_ApplyMask");
  auto Layer16_Attention_Z_Softmax =
      odla_Softmax(Layer16_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer16_Attention_Z_Softmax");
  auto Layer16_Attention_Z_MatMul_1 =
      odla_Gemm(Layer16_Attention_Z_Softmax, 0, Layer16_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer16_Attention_Z_MatMul_1");
  auto Layer16_Attention_Z_Transpose = odla_Transpose(
      Layer16_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer16_Attention_Z_Transpose");
  auto Layer16_Attention_Z_Reshape = odla_Reshape(
      Layer16_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer16_Attention_Z_Reshape");
  auto Layer16_Attention_MatMul_3 =
      odla_Gemm(Layer16_Attention_Z_Reshape, 0, Layer16_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer16_Attention_MatMul_3");
  auto Layer16_Attention_Add =
      odla_Add(Layer16_Attention_MatMul_3, Layer16_Attention_Out_Bias_,
               (const odla_value_id) "Layer16_Attention_Add");
  auto Layer16_Attention_Add_1 =
      odla_Add(Layer15_FF_GroupNormalization, Layer16_Attention_Add,
               (const odla_value_id) "Layer16_Attention_Add_1");
  auto Layer16_Attention_GroupNormalization = odla_GroupNormalization(
      Layer16_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer16_Attention_Gamma_, Layer16_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer16_Attention_GroupNormalization");
  auto Layer16_FF_1_MatMul =
      odla_Gemm(Layer16_Attention_GroupNormalization, 0, Layer16_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer16_FF_1_MatMul");
  auto Layer16_FF_1_Add = odla_Add(Layer16_FF_1_MatMul, Layer16_FF_1_B_,
                                   (const odla_value_id) "Layer16_FF_1_Add");
  auto Layer16_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer16_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer16_FF_Gelu0"}});
  auto Layer16_FF_Gelu0 = Layer16_FF_Gelu0_array.values[0];
  auto Layer16_FF_2_MatMul =
      odla_Gemm(Layer16_FF_Gelu0, 0, Layer16_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer16_FF_2_MatMul");
  auto Layer16_FF_2_Add = odla_Add(Layer16_FF_2_MatMul, Layer16_FF_2_B_,
                                   (const odla_value_id) "Layer16_FF_2_Add");
  auto Layer16_FF_Add =
      odla_Add(Layer16_Attention_GroupNormalization, Layer16_FF_2_Add,
               (const odla_value_id) "Layer16_FF_Add");
  auto Layer16_FF_GroupNormalization = odla_GroupNormalization(
      Layer16_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer16_FF_Gamma_, Layer16_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer16_FF_GroupNormalization");
  auto Layer17_Attention_MatMul =
      odla_Gemm(Layer16_FF_GroupNormalization, 0, Layer17_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer17_Attention_MatMul");
  auto Layer17_Attention_MatMul_1 =
      odla_Gemm(Layer16_FF_GroupNormalization, 0, Layer17_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer17_Attention_MatMul_1");
  auto Layer17_Attention_MatMul_2 =
      odla_Gemm(Layer16_FF_GroupNormalization, 0, Layer17_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer17_Attention_MatMul_2");
  auto Layer17_Attention_Reshape = odla_Reshape(
      Layer17_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer17_Attention_Reshape");
  auto Layer17_Attention_Transpose = odla_Transpose(
      Layer17_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer17_Attention_Transpose");
  auto Layer17_Attention_Reshape_1 = odla_Reshape(
      Layer17_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer17_Attention_Reshape_1");
  auto Layer17_Attention_Transpose_1 = odla_Transpose(
      Layer17_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer17_Attention_Transpose_1");
  auto Layer17_Attention_Reshape_2 = odla_Reshape(
      Layer17_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer17_Attention_Reshape_2");
  auto Layer17_Attention_Transpose_2 = odla_Transpose(
      Layer17_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer17_Attention_Transpose_2");
  auto Layer17_Attention_Z_MatMul =
      odla_Gemm(Layer17_Attention_Transpose, 0, Layer17_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer17_Attention_Z_MatMul");
  auto Layer17_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer17_Attention_Z_Mask_Reshape");
  auto Layer17_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer17_Attention_Z_Mask_Reshape,
                            Layer17_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer17_Attention_Z_Mask_AttentionMask0"}});
  auto Layer17_Attention_Z_Mask_AttentionMask0 =
      Layer17_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer17_Attention_Z_ApplyMask = odla_Add(
      Layer17_Attention_Z_MatMul, Layer17_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer17_Attention_Z_ApplyMask");
  auto Layer17_Attention_Z_Softmax =
      odla_Softmax(Layer17_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer17_Attention_Z_Softmax");
  auto Layer17_Attention_Z_MatMul_1 =
      odla_Gemm(Layer17_Attention_Z_Softmax, 0, Layer17_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer17_Attention_Z_MatMul_1");
  auto Layer17_Attention_Z_Transpose = odla_Transpose(
      Layer17_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer17_Attention_Z_Transpose");
  auto Layer17_Attention_Z_Reshape = odla_Reshape(
      Layer17_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer17_Attention_Z_Reshape");
  auto Layer17_Attention_MatMul_3 =
      odla_Gemm(Layer17_Attention_Z_Reshape, 0, Layer17_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer17_Attention_MatMul_3");
  auto Layer17_Attention_Add =
      odla_Add(Layer17_Attention_MatMul_3, Layer17_Attention_Out_Bias_,
               (const odla_value_id) "Layer17_Attention_Add");
  auto Layer17_Attention_Add_1 =
      odla_Add(Layer16_FF_GroupNormalization, Layer17_Attention_Add,
               (const odla_value_id) "Layer17_Attention_Add_1");
  auto Layer17_Attention_GroupNormalization = odla_GroupNormalization(
      Layer17_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer17_Attention_Gamma_, Layer17_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer17_Attention_GroupNormalization");
  auto Layer17_FF_1_MatMul =
      odla_Gemm(Layer17_Attention_GroupNormalization, 0, Layer17_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer17_FF_1_MatMul");
  auto Layer17_FF_1_Add = odla_Add(Layer17_FF_1_MatMul, Layer17_FF_1_B_,
                                   (const odla_value_id) "Layer17_FF_1_Add");
  auto Layer17_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer17_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer17_FF_Gelu0"}});
  auto Layer17_FF_Gelu0 = Layer17_FF_Gelu0_array.values[0];
  auto Layer17_FF_2_MatMul =
      odla_Gemm(Layer17_FF_Gelu0, 0, Layer17_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer17_FF_2_MatMul");
  auto Layer17_FF_2_Add = odla_Add(Layer17_FF_2_MatMul, Layer17_FF_2_B_,
                                   (const odla_value_id) "Layer17_FF_2_Add");
  auto Layer17_FF_Add =
      odla_Add(Layer17_Attention_GroupNormalization, Layer17_FF_2_Add,
               (const odla_value_id) "Layer17_FF_Add");
  auto Layer17_FF_GroupNormalization = odla_GroupNormalization(
      Layer17_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer17_FF_Gamma_, Layer17_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer17_FF_GroupNormalization");
  auto Layer18_Attention_MatMul =
      odla_Gemm(Layer17_FF_GroupNormalization, 0, Layer18_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer18_Attention_MatMul");
  auto Layer18_Attention_MatMul_1 =
      odla_Gemm(Layer17_FF_GroupNormalization, 0, Layer18_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer18_Attention_MatMul_1");
  auto Layer18_Attention_MatMul_2 =
      odla_Gemm(Layer17_FF_GroupNormalization, 0, Layer18_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer18_Attention_MatMul_2");
  auto Layer18_Attention_Reshape = odla_Reshape(
      Layer18_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer18_Attention_Reshape");
  auto Layer18_Attention_Transpose = odla_Transpose(
      Layer18_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer18_Attention_Transpose");
  auto Layer18_Attention_Reshape_1 = odla_Reshape(
      Layer18_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer18_Attention_Reshape_1");
  auto Layer18_Attention_Transpose_1 = odla_Transpose(
      Layer18_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer18_Attention_Transpose_1");
  auto Layer18_Attention_Reshape_2 = odla_Reshape(
      Layer18_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer18_Attention_Reshape_2");
  auto Layer18_Attention_Transpose_2 = odla_Transpose(
      Layer18_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer18_Attention_Transpose_2");
  auto Layer18_Attention_Z_MatMul =
      odla_Gemm(Layer18_Attention_Transpose, 0, Layer18_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer18_Attention_Z_MatMul");
  auto Layer18_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer18_Attention_Z_Mask_Reshape");
  auto Layer18_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer18_Attention_Z_Mask_Reshape,
                            Layer18_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer18_Attention_Z_Mask_AttentionMask0"}});
  auto Layer18_Attention_Z_Mask_AttentionMask0 =
      Layer18_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer18_Attention_Z_ApplyMask = odla_Add(
      Layer18_Attention_Z_MatMul, Layer18_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer18_Attention_Z_ApplyMask");
  auto Layer18_Attention_Z_Softmax =
      odla_Softmax(Layer18_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer18_Attention_Z_Softmax");
  auto Layer18_Attention_Z_MatMul_1 =
      odla_Gemm(Layer18_Attention_Z_Softmax, 0, Layer18_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer18_Attention_Z_MatMul_1");
  auto Layer18_Attention_Z_Transpose = odla_Transpose(
      Layer18_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer18_Attention_Z_Transpose");
  auto Layer18_Attention_Z_Reshape = odla_Reshape(
      Layer18_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer18_Attention_Z_Reshape");
  auto Layer18_Attention_MatMul_3 =
      odla_Gemm(Layer18_Attention_Z_Reshape, 0, Layer18_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer18_Attention_MatMul_3");
  auto Layer18_Attention_Add =
      odla_Add(Layer18_Attention_MatMul_3, Layer18_Attention_Out_Bias_,
               (const odla_value_id) "Layer18_Attention_Add");
  auto Layer18_Attention_Add_1 =
      odla_Add(Layer17_FF_GroupNormalization, Layer18_Attention_Add,
               (const odla_value_id) "Layer18_Attention_Add_1");
  auto Layer18_Attention_GroupNormalization = odla_GroupNormalization(
      Layer18_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer18_Attention_Gamma_, Layer18_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer18_Attention_GroupNormalization");
  auto Layer18_FF_1_MatMul =
      odla_Gemm(Layer18_Attention_GroupNormalization, 0, Layer18_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer18_FF_1_MatMul");
  auto Layer18_FF_1_Add = odla_Add(Layer18_FF_1_MatMul, Layer18_FF_1_B_,
                                   (const odla_value_id) "Layer18_FF_1_Add");
  auto Layer18_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer18_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer18_FF_Gelu0"}});
  auto Layer18_FF_Gelu0 = Layer18_FF_Gelu0_array.values[0];
  auto Layer18_FF_2_MatMul =
      odla_Gemm(Layer18_FF_Gelu0, 0, Layer18_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer18_FF_2_MatMul");
  auto Layer18_FF_2_Add = odla_Add(Layer18_FF_2_MatMul, Layer18_FF_2_B_,
                                   (const odla_value_id) "Layer18_FF_2_Add");
  auto Layer18_FF_Add =
      odla_Add(Layer18_Attention_GroupNormalization, Layer18_FF_2_Add,
               (const odla_value_id) "Layer18_FF_Add");
  auto Layer18_FF_GroupNormalization = odla_GroupNormalization(
      Layer18_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer18_FF_Gamma_, Layer18_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer18_FF_GroupNormalization");
  auto Layer19_Attention_MatMul =
      odla_Gemm(Layer18_FF_GroupNormalization, 0, Layer19_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer19_Attention_MatMul");
  auto Layer19_Attention_MatMul_1 =
      odla_Gemm(Layer18_FF_GroupNormalization, 0, Layer19_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer19_Attention_MatMul_1");
  auto Layer19_Attention_MatMul_2 =
      odla_Gemm(Layer18_FF_GroupNormalization, 0, Layer19_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer19_Attention_MatMul_2");
  auto Layer19_Attention_Reshape = odla_Reshape(
      Layer19_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer19_Attention_Reshape");
  auto Layer19_Attention_Transpose = odla_Transpose(
      Layer19_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer19_Attention_Transpose");
  auto Layer19_Attention_Reshape_1 = odla_Reshape(
      Layer19_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer19_Attention_Reshape_1");
  auto Layer19_Attention_Transpose_1 = odla_Transpose(
      Layer19_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer19_Attention_Transpose_1");
  auto Layer19_Attention_Reshape_2 = odla_Reshape(
      Layer19_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer19_Attention_Reshape_2");
  auto Layer19_Attention_Transpose_2 = odla_Transpose(
      Layer19_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer19_Attention_Transpose_2");
  auto Layer19_Attention_Z_MatMul =
      odla_Gemm(Layer19_Attention_Transpose, 0, Layer19_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer19_Attention_Z_MatMul");
  auto Layer19_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer19_Attention_Z_Mask_Reshape");
  auto Layer19_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer19_Attention_Z_Mask_Reshape,
                            Layer19_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer19_Attention_Z_Mask_AttentionMask0"}});
  auto Layer19_Attention_Z_Mask_AttentionMask0 =
      Layer19_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer19_Attention_Z_ApplyMask = odla_Add(
      Layer19_Attention_Z_MatMul, Layer19_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer19_Attention_Z_ApplyMask");
  auto Layer19_Attention_Z_Softmax =
      odla_Softmax(Layer19_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer19_Attention_Z_Softmax");
  auto Layer19_Attention_Z_MatMul_1 =
      odla_Gemm(Layer19_Attention_Z_Softmax, 0, Layer19_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer19_Attention_Z_MatMul_1");
  auto Layer19_Attention_Z_Transpose = odla_Transpose(
      Layer19_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer19_Attention_Z_Transpose");
  auto Layer19_Attention_Z_Reshape = odla_Reshape(
      Layer19_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer19_Attention_Z_Reshape");
  auto Layer19_Attention_MatMul_3 =
      odla_Gemm(Layer19_Attention_Z_Reshape, 0, Layer19_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer19_Attention_MatMul_3");
  auto Layer19_Attention_Add =
      odla_Add(Layer19_Attention_MatMul_3, Layer19_Attention_Out_Bias_,
               (const odla_value_id) "Layer19_Attention_Add");
  auto Layer19_Attention_Add_1 =
      odla_Add(Layer18_FF_GroupNormalization, Layer19_Attention_Add,
               (const odla_value_id) "Layer19_Attention_Add_1");
  auto Layer19_Attention_GroupNormalization = odla_GroupNormalization(
      Layer19_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer19_Attention_Gamma_, Layer19_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer19_Attention_GroupNormalization");
  auto Layer19_FF_1_MatMul =
      odla_Gemm(Layer19_Attention_GroupNormalization, 0, Layer19_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer19_FF_1_MatMul");
  auto Layer19_FF_1_Add = odla_Add(Layer19_FF_1_MatMul, Layer19_FF_1_B_,
                                   (const odla_value_id) "Layer19_FF_1_Add");
  auto Layer19_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer19_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer19_FF_Gelu0"}});
  auto Layer19_FF_Gelu0 = Layer19_FF_Gelu0_array.values[0];
  auto Layer19_FF_2_MatMul =
      odla_Gemm(Layer19_FF_Gelu0, 0, Layer19_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer19_FF_2_MatMul");
  auto Layer19_FF_2_Add = odla_Add(Layer19_FF_2_MatMul, Layer19_FF_2_B_,
                                   (const odla_value_id) "Layer19_FF_2_Add");
  auto Layer19_FF_Add =
      odla_Add(Layer19_Attention_GroupNormalization, Layer19_FF_2_Add,
               (const odla_value_id) "Layer19_FF_Add");
  auto Layer19_FF_GroupNormalization = odla_GroupNormalization(
      Layer19_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer19_FF_Gamma_, Layer19_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer19_FF_GroupNormalization");
  auto Layer20_Attention_MatMul =
      odla_Gemm(Layer19_FF_GroupNormalization, 0, Layer20_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer20_Attention_MatMul");
  auto Layer20_Attention_MatMul_1 =
      odla_Gemm(Layer19_FF_GroupNormalization, 0, Layer20_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer20_Attention_MatMul_1");
  auto Layer20_Attention_MatMul_2 =
      odla_Gemm(Layer19_FF_GroupNormalization, 0, Layer20_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer20_Attention_MatMul_2");
  auto Layer20_Attention_Reshape = odla_Reshape(
      Layer20_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer20_Attention_Reshape");
  auto Layer20_Attention_Transpose = odla_Transpose(
      Layer20_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer20_Attention_Transpose");
  auto Layer20_Attention_Reshape_1 = odla_Reshape(
      Layer20_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer20_Attention_Reshape_1");
  auto Layer20_Attention_Transpose_1 = odla_Transpose(
      Layer20_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer20_Attention_Transpose_1");
  auto Layer20_Attention_Reshape_2 = odla_Reshape(
      Layer20_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer20_Attention_Reshape_2");
  auto Layer20_Attention_Transpose_2 = odla_Transpose(
      Layer20_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer20_Attention_Transpose_2");
  auto Layer20_Attention_Z_MatMul =
      odla_Gemm(Layer20_Attention_Transpose, 0, Layer20_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer20_Attention_Z_MatMul");
  auto Layer20_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer20_Attention_Z_Mask_Reshape");
  auto Layer20_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer20_Attention_Z_Mask_Reshape,
                            Layer20_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer20_Attention_Z_Mask_AttentionMask0"}});
  auto Layer20_Attention_Z_Mask_AttentionMask0 =
      Layer20_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer20_Attention_Z_ApplyMask = odla_Add(
      Layer20_Attention_Z_MatMul, Layer20_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer20_Attention_Z_ApplyMask");
  auto Layer20_Attention_Z_Softmax =
      odla_Softmax(Layer20_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer20_Attention_Z_Softmax");
  auto Layer20_Attention_Z_MatMul_1 =
      odla_Gemm(Layer20_Attention_Z_Softmax, 0, Layer20_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer20_Attention_Z_MatMul_1");
  auto Layer20_Attention_Z_Transpose = odla_Transpose(
      Layer20_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer20_Attention_Z_Transpose");
  auto Layer20_Attention_Z_Reshape = odla_Reshape(
      Layer20_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer20_Attention_Z_Reshape");
  auto Layer20_Attention_MatMul_3 =
      odla_Gemm(Layer20_Attention_Z_Reshape, 0, Layer20_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer20_Attention_MatMul_3");
  auto Layer20_Attention_Add =
      odla_Add(Layer20_Attention_MatMul_3, Layer20_Attention_Out_Bias_,
               (const odla_value_id) "Layer20_Attention_Add");
  auto Layer20_Attention_Add_1 =
      odla_Add(Layer19_FF_GroupNormalization, Layer20_Attention_Add,
               (const odla_value_id) "Layer20_Attention_Add_1");
  auto Layer20_Attention_GroupNormalization = odla_GroupNormalization(
      Layer20_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer20_Attention_Gamma_, Layer20_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer20_Attention_GroupNormalization");
  auto Layer20_FF_1_MatMul =
      odla_Gemm(Layer20_Attention_GroupNormalization, 0, Layer20_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer20_FF_1_MatMul");
  auto Layer20_FF_1_Add = odla_Add(Layer20_FF_1_MatMul, Layer20_FF_1_B_,
                                   (const odla_value_id) "Layer20_FF_1_Add");
  auto Layer20_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer20_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer20_FF_Gelu0"}});
  auto Layer20_FF_Gelu0 = Layer20_FF_Gelu0_array.values[0];
  auto Layer20_FF_2_MatMul =
      odla_Gemm(Layer20_FF_Gelu0, 0, Layer20_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer20_FF_2_MatMul");
  auto Layer20_FF_2_Add = odla_Add(Layer20_FF_2_MatMul, Layer20_FF_2_B_,
                                   (const odla_value_id) "Layer20_FF_2_Add");
  auto Layer20_FF_Add =
      odla_Add(Layer20_Attention_GroupNormalization, Layer20_FF_2_Add,
               (const odla_value_id) "Layer20_FF_Add");
  auto Layer20_FF_GroupNormalization = odla_GroupNormalization(
      Layer20_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer20_FF_Gamma_, Layer20_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer20_FF_GroupNormalization");
  auto Layer21_Attention_MatMul =
      odla_Gemm(Layer20_FF_GroupNormalization, 0, Layer21_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer21_Attention_MatMul");
  auto Layer21_Attention_MatMul_1 =
      odla_Gemm(Layer20_FF_GroupNormalization, 0, Layer21_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer21_Attention_MatMul_1");
  auto Layer21_Attention_MatMul_2 =
      odla_Gemm(Layer20_FF_GroupNormalization, 0, Layer21_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer21_Attention_MatMul_2");
  auto Layer21_Attention_Reshape = odla_Reshape(
      Layer21_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer21_Attention_Reshape");
  auto Layer21_Attention_Transpose = odla_Transpose(
      Layer21_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer21_Attention_Transpose");
  auto Layer21_Attention_Reshape_1 = odla_Reshape(
      Layer21_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer21_Attention_Reshape_1");
  auto Layer21_Attention_Transpose_1 = odla_Transpose(
      Layer21_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer21_Attention_Transpose_1");
  auto Layer21_Attention_Reshape_2 = odla_Reshape(
      Layer21_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer21_Attention_Reshape_2");
  auto Layer21_Attention_Transpose_2 = odla_Transpose(
      Layer21_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer21_Attention_Transpose_2");
  auto Layer21_Attention_Z_MatMul =
      odla_Gemm(Layer21_Attention_Transpose, 0, Layer21_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer21_Attention_Z_MatMul");
  auto Layer21_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer21_Attention_Z_Mask_Reshape");
  auto Layer21_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer21_Attention_Z_Mask_Reshape,
                            Layer21_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer21_Attention_Z_Mask_AttentionMask0"}});
  auto Layer21_Attention_Z_Mask_AttentionMask0 =
      Layer21_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer21_Attention_Z_ApplyMask = odla_Add(
      Layer21_Attention_Z_MatMul, Layer21_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer21_Attention_Z_ApplyMask");
  auto Layer21_Attention_Z_Softmax =
      odla_Softmax(Layer21_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer21_Attention_Z_Softmax");
  auto Layer21_Attention_Z_MatMul_1 =
      odla_Gemm(Layer21_Attention_Z_Softmax, 0, Layer21_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer21_Attention_Z_MatMul_1");
  auto Layer21_Attention_Z_Transpose = odla_Transpose(
      Layer21_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer21_Attention_Z_Transpose");
  auto Layer21_Attention_Z_Reshape = odla_Reshape(
      Layer21_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer21_Attention_Z_Reshape");
  auto Layer21_Attention_MatMul_3 =
      odla_Gemm(Layer21_Attention_Z_Reshape, 0, Layer21_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer21_Attention_MatMul_3");
  auto Layer21_Attention_Add =
      odla_Add(Layer21_Attention_MatMul_3, Layer21_Attention_Out_Bias_,
               (const odla_value_id) "Layer21_Attention_Add");
  auto Layer21_Attention_Add_1 =
      odla_Add(Layer20_FF_GroupNormalization, Layer21_Attention_Add,
               (const odla_value_id) "Layer21_Attention_Add_1");
  auto Layer21_Attention_GroupNormalization = odla_GroupNormalization(
      Layer21_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer21_Attention_Gamma_, Layer21_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer21_Attention_GroupNormalization");
  auto Layer21_FF_1_MatMul =
      odla_Gemm(Layer21_Attention_GroupNormalization, 0, Layer21_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer21_FF_1_MatMul");
  auto Layer21_FF_1_Add = odla_Add(Layer21_FF_1_MatMul, Layer21_FF_1_B_,
                                   (const odla_value_id) "Layer21_FF_1_Add");
  auto Layer21_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer21_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer21_FF_Gelu0"}});
  auto Layer21_FF_Gelu0 = Layer21_FF_Gelu0_array.values[0];
  auto Layer21_FF_2_MatMul =
      odla_Gemm(Layer21_FF_Gelu0, 0, Layer21_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer21_FF_2_MatMul");
  auto Layer21_FF_2_Add = odla_Add(Layer21_FF_2_MatMul, Layer21_FF_2_B_,
                                   (const odla_value_id) "Layer21_FF_2_Add");
  auto Layer21_FF_Add =
      odla_Add(Layer21_Attention_GroupNormalization, Layer21_FF_2_Add,
               (const odla_value_id) "Layer21_FF_Add");
  auto Layer21_FF_GroupNormalization = odla_GroupNormalization(
      Layer21_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer21_FF_Gamma_, Layer21_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer21_FF_GroupNormalization");
  auto Layer22_Attention_MatMul =
      odla_Gemm(Layer21_FF_GroupNormalization, 0, Layer22_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer22_Attention_MatMul");
  auto Layer22_Attention_MatMul_1 =
      odla_Gemm(Layer21_FF_GroupNormalization, 0, Layer22_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer22_Attention_MatMul_1");
  auto Layer22_Attention_MatMul_2 =
      odla_Gemm(Layer21_FF_GroupNormalization, 0, Layer22_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer22_Attention_MatMul_2");
  auto Layer22_Attention_Reshape = odla_Reshape(
      Layer22_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer22_Attention_Reshape");
  auto Layer22_Attention_Transpose = odla_Transpose(
      Layer22_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer22_Attention_Transpose");
  auto Layer22_Attention_Reshape_1 = odla_Reshape(
      Layer22_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer22_Attention_Reshape_1");
  auto Layer22_Attention_Transpose_1 = odla_Transpose(
      Layer22_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer22_Attention_Transpose_1");
  auto Layer22_Attention_Reshape_2 = odla_Reshape(
      Layer22_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer22_Attention_Reshape_2");
  auto Layer22_Attention_Transpose_2 = odla_Transpose(
      Layer22_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer22_Attention_Transpose_2");
  auto Layer22_Attention_Z_MatMul =
      odla_Gemm(Layer22_Attention_Transpose, 0, Layer22_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer22_Attention_Z_MatMul");
  auto Layer22_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer22_Attention_Z_Mask_Reshape");
  auto Layer22_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer22_Attention_Z_Mask_Reshape,
                            Layer22_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer22_Attention_Z_Mask_AttentionMask0"}});
  auto Layer22_Attention_Z_Mask_AttentionMask0 =
      Layer22_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer22_Attention_Z_ApplyMask = odla_Add(
      Layer22_Attention_Z_MatMul, Layer22_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer22_Attention_Z_ApplyMask");
  auto Layer22_Attention_Z_Softmax =
      odla_Softmax(Layer22_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer22_Attention_Z_Softmax");
  auto Layer22_Attention_Z_MatMul_1 =
      odla_Gemm(Layer22_Attention_Z_Softmax, 0, Layer22_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer22_Attention_Z_MatMul_1");
  auto Layer22_Attention_Z_Transpose = odla_Transpose(
      Layer22_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer22_Attention_Z_Transpose");
  auto Layer22_Attention_Z_Reshape = odla_Reshape(
      Layer22_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer22_Attention_Z_Reshape");
  auto Layer22_Attention_MatMul_3 =
      odla_Gemm(Layer22_Attention_Z_Reshape, 0, Layer22_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer22_Attention_MatMul_3");
  auto Layer22_Attention_Add =
      odla_Add(Layer22_Attention_MatMul_3, Layer22_Attention_Out_Bias_,
               (const odla_value_id) "Layer22_Attention_Add");
  auto Layer22_Attention_Add_1 =
      odla_Add(Layer21_FF_GroupNormalization, Layer22_Attention_Add,
               (const odla_value_id) "Layer22_Attention_Add_1");
  auto Layer22_Attention_GroupNormalization = odla_GroupNormalization(
      Layer22_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer22_Attention_Gamma_, Layer22_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer22_Attention_GroupNormalization");
  auto Layer22_FF_1_MatMul =
      odla_Gemm(Layer22_Attention_GroupNormalization, 0, Layer22_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer22_FF_1_MatMul");
  auto Layer22_FF_1_Add = odla_Add(Layer22_FF_1_MatMul, Layer22_FF_1_B_,
                                   (const odla_value_id) "Layer22_FF_1_Add");
  auto Layer22_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer22_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer22_FF_Gelu0"}});
  auto Layer22_FF_Gelu0 = Layer22_FF_Gelu0_array.values[0];
  auto Layer22_FF_2_MatMul =
      odla_Gemm(Layer22_FF_Gelu0, 0, Layer22_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer22_FF_2_MatMul");
  auto Layer22_FF_2_Add = odla_Add(Layer22_FF_2_MatMul, Layer22_FF_2_B_,
                                   (const odla_value_id) "Layer22_FF_2_Add");
  auto Layer22_FF_Add =
      odla_Add(Layer22_Attention_GroupNormalization, Layer22_FF_2_Add,
               (const odla_value_id) "Layer22_FF_Add");
  auto Layer22_FF_GroupNormalization = odla_GroupNormalization(
      Layer22_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer22_FF_Gamma_, Layer22_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer22_FF_GroupNormalization");
  auto Layer23_Attention_MatMul =
      odla_Gemm(Layer22_FF_GroupNormalization, 0, Layer23_Attention_Q_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer23_Attention_MatMul");
  auto Layer23_Attention_MatMul_1 =
      odla_Gemm(Layer22_FF_GroupNormalization, 0, Layer23_Attention_K_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer23_Attention_MatMul_1");
  auto Layer23_Attention_MatMul_2 =
      odla_Gemm(Layer22_FF_GroupNormalization, 0, Layer23_Attention_V_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer23_Attention_MatMul_2");
  auto Layer23_Attention_Reshape = odla_Reshape(
      Layer23_Attention_MatMul, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer23_Attention_Reshape");
  auto Layer23_Attention_Transpose = odla_Transpose(
      Layer23_Attention_Reshape, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer23_Attention_Transpose");
  auto Layer23_Attention_Reshape_1 = odla_Reshape(
      Layer23_Attention_MatMul_1, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer23_Attention_Reshape_1");
  auto Layer23_Attention_Transpose_1 = odla_Transpose(
      Layer23_Attention_Reshape_1, {.size = 4, .dims = {0, 2, 3, 1}},
      {.size = 4, .dims = {10, 16, 64, 384}},
      (const odla_value_id) "Layer23_Attention_Transpose_1");
  auto Layer23_Attention_Reshape_2 = odla_Reshape(
      Layer23_Attention_MatMul_2, {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer23_Attention_Reshape_2");
  auto Layer23_Attention_Transpose_2 = odla_Transpose(
      Layer23_Attention_Reshape_2, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 16, 384, 64}},
      (const odla_value_id) "Layer23_Attention_Transpose_2");
  auto Layer23_Attention_Z_MatMul =
      odla_Gemm(Layer23_Attention_Transpose, 0, Layer23_Attention_Transpose_1,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 384}},
                (const odla_value_id) "Layer23_Attention_Z_MatMul");
  auto Layer23_Attention_Z_Mask_Reshape =
      odla_Reshape(input_mask, {.size = 2, .dims = {10, 384}},
                   (const odla_value_id) "Layer23_Attention_Z_Mask_Reshape");
  auto Layer23_Attention_Z_Mask_AttentionMask0_array = odla_CustomOp(
      (odla_values){.size = 2,
                    .values =
                        {
                            Layer23_Attention_Z_Mask_Reshape,
                            Layer23_Attention_Z_MatMul,
                        }},
      "custom_IpuAttentionMask", "custom_IpuAttentionMask",
      {.size = 1,
       .value_ids = {
           (const odla_value_id) "Layer23_Attention_Z_Mask_AttentionMask0"}});
  auto Layer23_Attention_Z_Mask_AttentionMask0 =
      Layer23_Attention_Z_Mask_AttentionMask0_array.values[0];
  auto Layer23_Attention_Z_ApplyMask = odla_Add(
      Layer23_Attention_Z_MatMul, Layer23_Attention_Z_Mask_AttentionMask0,
      (const odla_value_id) "Layer23_Attention_Z_ApplyMask");
  auto Layer23_Attention_Z_Softmax =
      odla_Softmax(Layer23_Attention_Z_ApplyMask, -1,
                   (const odla_value_id) "Layer23_Attention_Z_Softmax");
  auto Layer23_Attention_Z_MatMul_1 =
      odla_Gemm(Layer23_Attention_Z_Softmax, 0, Layer23_Attention_Transpose_2,
                0, 1, 0, nullptr, {.size = 4, .dims = {10, 16, 384, 64}},
                (const odla_value_id) "Layer23_Attention_Z_MatMul_1");
  auto Layer23_Attention_Z_Transpose = odla_Transpose(
      Layer23_Attention_Z_MatMul_1, {.size = 4, .dims = {0, 2, 1, 3}},
      {.size = 4, .dims = {10, 384, 16, 64}},
      (const odla_value_id) "Layer23_Attention_Z_Transpose");
  auto Layer23_Attention_Z_Reshape = odla_Reshape(
      Layer23_Attention_Z_Transpose, {.size = 2, .dims = {3840, 1024}},
      (const odla_value_id) "Layer23_Attention_Z_Reshape");
  auto Layer23_Attention_MatMul_3 =
      odla_Gemm(Layer23_Attention_Z_Reshape, 0, Layer23_Attention_Out_, 0, 1, 0,
                nullptr, {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer23_Attention_MatMul_3");
  auto Layer23_Attention_Add =
      odla_Add(Layer23_Attention_MatMul_3, Layer23_Attention_Out_Bias_,
               (const odla_value_id) "Layer23_Attention_Add");
  auto Layer23_Attention_Add_1 =
      odla_Add(Layer22_FF_GroupNormalization, Layer23_Attention_Add,
               (const odla_value_id) "Layer23_Attention_Add_1");
  auto Layer23_Attention_GroupNormalization = odla_GroupNormalization(
      Layer23_Attention_Add_1, odla_memory_layout::ODLA_CHANNELS_FIRST, 1,
      0.001, Layer23_Attention_Gamma_, Layer23_Attention_Beta_, 1, 0,
      (const odla_value_id) "Layer23_Attention_GroupNormalization");
  auto Layer23_FF_1_MatMul =
      odla_Gemm(Layer23_Attention_GroupNormalization, 0, Layer23_FF_1_W_, 0, 1,
                0, nullptr, {.size = 2, .dims = {3840, 4096}},
                (const odla_value_id) "Layer23_FF_1_MatMul");
  auto Layer23_FF_1_Add = odla_Add(Layer23_FF_1_MatMul, Layer23_FF_1_B_,
                                   (const odla_value_id) "Layer23_FF_1_Add");
  auto Layer23_FF_Gelu0_array = odla_CustomOp(
      (odla_values){.size = 1,
                    .values =
                        {
                            Layer23_FF_1_Add,
                        }},
      "custom_IpuGelu", "custom_IpuGelu",
      {.size = 1, .value_ids = {(const odla_value_id) "Layer23_FF_Gelu0"}});
  auto Layer23_FF_Gelu0 = Layer23_FF_Gelu0_array.values[0];
  auto Layer23_FF_2_MatMul =
      odla_Gemm(Layer23_FF_Gelu0, 0, Layer23_FF_2_W_, 0, 1, 0, nullptr,
                {.size = 2, .dims = {3840, 1024}},
                (const odla_value_id) "Layer23_FF_2_MatMul");
  auto Layer23_FF_2_Add = odla_Add(Layer23_FF_2_MatMul, Layer23_FF_2_B_,
                                   (const odla_value_id) "Layer23_FF_2_Add");
  auto Layer23_FF_Add =
      odla_Add(Layer23_Attention_GroupNormalization, Layer23_FF_2_Add,
               (const odla_value_id) "Layer23_FF_Add");
  auto Layer23_FF_GroupNormalization = odla_GroupNormalization(
      Layer23_FF_Add, odla_memory_layout::ODLA_CHANNELS_FIRST, 1, 0.001,
      Layer23_FF_Gamma_, Layer23_FF_Beta_, 1, 0,
      (const odla_value_id) "Layer23_FF_GroupNormalization");
  auto Squad_Gemm = odla_Gemm(
      Layer23_FF_GroupNormalization, 0, Squad_SquadW_, 0, 1, 0, Squad_SquadB_,
      {.size = 2, .dims = {3840, 2}}, (const odla_value_id) "Squad_Gemm");
  odla_SetValueAsOutput(Squad_Gemm);
  return ODLA_SUCCESS;
}
int model_fini() {
  if (Comp != nullptr) {
    return odla_DestroyComputation(Comp);
  }
  return ODLA_SUCCESS;
}
int model_init() {
  odla_status status = ODLA_SUCCESS;
  if (Comp == nullptr) {
    status = odla_CreateComputation(&Comp);
    if (status != ODLA_SUCCESS) {
      return status;
    }
    status = (odla_status)model_helper(Comp);
  }
  return status;
}
int model_run(int num_inputs, const void *inputs[], int num_outputs,
              void *outputs[], int batch_size) {
  odla_status status = ODLA_SUCCESS;
  status = (odla_status)model_init();
  if (status != ODLA_SUCCESS) {
    return status;
  }
  static odla_context Ctx;
  if (Ctx == nullptr) {
    status = odla_CreateContext(&Ctx);
    if (status != ODLA_SUCCESS) {
      return status;
    }
  }
  status =
      odla_BindToArgumentById((const odla_value_id) "indices", inputs[0], Ctx);
  if (status != ODLA_SUCCESS) {
    return status;
  }
  status = odla_BindToArgumentById((const odla_value_id) "input_mask",
                                   inputs[1], Ctx);
  if (status != ODLA_SUCCESS) {
    return status;
  }
  status = odla_BindToArgumentById((const odla_value_id) "positions", inputs[2],
                                   Ctx);
  if (status != ODLA_SUCCESS) {
    return status;
  }
  status =
      odla_BindToArgumentById((const odla_value_id) "segments", inputs[3], Ctx);
  if (status != ODLA_SUCCESS) {
    return status;
  }
  status = odla_BindToOutputById((const odla_value_id) "Squad_Gemm", outputs[0],
                                 Ctx);
  if (status != ODLA_SUCCESS) {
    return status;
  }
  return odla_ExecuteComputation(Comp, Ctx, ODLA_COMPUTE_INFERENCE, nullptr);
}
